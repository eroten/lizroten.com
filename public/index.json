[{"authors":null,"categories":null,"content":"I am a data scientist and cartographer based out of St. Paul, Minnesota. I primarily work in R, cleaning and organizing data, developing organization specific R packages, and developing R Shiny interactive data visualizations.\n\r Download my resumé.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1611440296,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"lizroten.com/author/liz-roten/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"lizroten.com/author/liz-roten/","section":"authors","summary":"I am a data scientist and cartographer based out of St. Paul, Minnesota. I primarily work in R, cleaning and organizing data, developing organization specific R packages, and developing R Shiny interactive data visualizations.","tags":null,"title":"Liz Roten","type":"authors"},{"authors":["吳恩達"],"categories":null,"content":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bb560906b6a99893cc21387348c0b074","permalink":"lizroten.com/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"lizroten.com/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"吳恩達","type":"authors"},{"authors":["Liz Roten"],"categories":["tutorial"],"content":"Around the holidays, my partner and I decided to bring a stationary exercise bike into our home. After many pros and cons lists, we opted for the Bowflex C6. I decided to try out this whole Peloton thing, and quickly found that the resistance adjustments are not equivalent between the Peloton bike and the C6. Thankfully, there is a wonderful subreddit just for this model! The folks there directed me to this conversion chart, which then led me to a 3D-printed plate to keep on my handlebars.\nAs I kept going along in my classes, all I could think was \u0026ldquo;What does this look like on a plot? What is the distribution?\u0026rdquo; Here is the result.\n## load packages\rlibrary(dplyr)\rlibrary(tidyr)\rlibrary(purrr)\rlibrary(ggplot2)\r## theme and Peloton(c) red\rsource(\u0026quot;theme.R\u0026quot;)\rpelo_red \u0026lt;- \u0026quot;#df1c2f\u0026quot;\r Create data table.\nconv_table \u0026lt;- tibble(C6 = c(0, 5, 9, 17, 25, 33, 49, 100),\rPeloton = c(0, 25, 30, 35, 40, 45, 50, 100),\rDifficulty = seq(from = 0, to = 10, length.out = 8 ))\rconv_table_long \u0026lt;- conv_table %\u0026gt;% gather(C6, Peloton, key = \u0026quot;Bike\u0026quot;, value = \u0026quot;Resistance\u0026quot;)\r Make the plot.\nplot \u0026lt;- ggplot(data = conv_table_long) +\rgeom_smooth(mapping = aes(x = Difficulty,\ry = Resistance,\rcolor = Bike),\rse = FALSE) + scale_color_manual(values = c(\u0026quot;white\u0026quot;,\rpelo_red),\rlabels = c(\u0026quot;Bowflex C6\u0026quot;,\r\u0026quot;Peloton\u0026quot;)) +\rscale_x_continuous(n.breaks = 3,\rlabels = c(\u0026quot;Easy\u0026quot;,\r\u0026quot;Hard\u0026quot;,\r\u0026quot;Impossible\u0026quot;)) +\rlabs(title = \u0026quot;Spin bike resistance\u0026quot;,\rsubtitle = \u0026quot;Peloton vs. Bowflex C6\u0026quot;,\rx = \u0026quot;Difficulty\u0026quot;,\rcaption = \u0026quot;@LizRoten 2021 | Data r/pelotoncycle\u0026quot;) +\rmy_theme  Display plot\nplot\r Update! I was scrolling through aforementioned r/SchwinnIC4_BowflexC6 and found a post by another data person!\nThe conversion formula u/raintower579 found is below\n$$ y = 0.0171x^2 - 0.64x + 9.1429 $$\nwhere x is the Peloton resistance and y is the C6 resistance.\npelo_conversion \u0026lt;- function(x){\r(0.0171*x^2) - (0.64*x) + 9.1429\r}\r To estimate the equivalence beyond 50, we can create a new tibble and apply the function to a sequence of Peloton resistance settings. Instructors don\u0026rsquo;t tend to call out any value below 20, so we can start there.\ntibble(peloton_resistance = seq(20,100,5)) %\u0026gt;% # create Peloton resistance sequence, 20-100 by 5s\rmutate(c6_resistance = round(pelo_conversion(peloton_resistance), 1))\r#\u0026gt; # A tibble: 17 x 2\r#\u0026gt; peloton_resistance c6_resistance\r#\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r#\u0026gt; 1 20 3.2\r#\u0026gt; 2 25 3.8\r#\u0026gt; 3 30 5.3\r#\u0026gt; 4 35 7.7\r#\u0026gt; 5 40 10.9\r#\u0026gt; 6 45 15 #\u0026gt; 7 50 19.9\r#\u0026gt; 8 55 25.7\r#\u0026gt; 9 60 32.3\r#\u0026gt; 10 65 39.8\r#\u0026gt; 11 70 48.1\r#\u0026gt; 12 75 57.3\r#\u0026gt; 13 80 67.4\r#\u0026gt; 14 85 78.3\r#\u0026gt; 15 90 90.1\r#\u0026gt; 16 95 103. #\u0026gt; 17 100 116.\r By this table, I\u0026rsquo;ve been making my classes much harder than necessary.\nWe can plot this function, as shown below.\nggplot(data = conv_table,\raes(x = Peloton,\ry = C6)) +\rgeom_function( fun = pelo_conversion,\rcolor = \u0026quot;white\u0026quot;) +\rstat_function(\rfun = pelo_conversion,\rgeom = \u0026quot;point\u0026quot;,\rcolor = pelo_red,\rsize = 2, n = 17) +\rscale_x_continuous(limits = c(20, 100)) +\rscale_y_continuous(limits = c(0, 100)) +\rlabs(title = \u0026quot;Peloton to Bowflex C6 resistance conversion\u0026quot;,\rx = \u0026quot;Peloton\u0026quot;,\ry = \u0026quot;Bowflex C6\u0026quot;,\rcaption = \u0026quot;@LizRoten 2021 | Data r/pelotoncycle | Model u/raintower579\u0026quot;) +\rmy_theme2\r The big, flashing caveat here is that every bike is calibrated just slightly differently, so this might not be correct for the machine in my bedroom.\n","date":1611619200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612117750,"objectID":"032bc7076db6aca417bda29c46727189","permalink":"lizroten.com/blog/bowflex-c6-to-peloton-resistance-conversion-plots/","publishdate":"2021-01-26T00:00:00Z","relpermalink":"lizroten.com/blog/bowflex-c6-to-peloton-resistance-conversion-plots/","section":"post","summary":"Around the holidays, my partner and I decided to bring a stationary exercise bike into our home. After many pros and cons lists, we opted for the Bowflex C6. I decided to try out this whole Peloton thing, and quickly found that the resistance adjustments are not equivalent between the Peloton bike and the C6.","tags":["ggplot2","peloton","personal"],"title":"Converting Peloton resistance to Bowflex C6 resistance","type":"post"},{"authors":[],"categories":["tutorial","cartography"],"content":"Goal Use {edgebundle} to map flight patterns over the US.\n# remotes::install_github(\u0026quot;schochastics/edgebundle\u0026quot;)\rlibrary(edgebundle)\rlibrary(igraph)\rlibrary(ggplot2)\rlibrary(ggraph)\rlibrary(dplyr)\rlibrary(sf)\rlibrary(tigris)\rset.seed(24601)\rmy_caption \u0026lt;- c(\u0026quot;Liz Roten (@LizRoten) | Data: openflights.org\u0026quot;)\r We also need to use the Python library, datashader. {edgebundle} ships with a nice function for installing all the dependencies.\nedgebundle:::install_bundle_py()\r Data prep The data we will use is us_flights, which is shipped with {edgebundle}. us_flights is a complex object.\nflights \u0026lt;- us_flights # name us_flights\rcoords \u0026lt;- cbind(V(flights)$longitude, V(flights)$latitude) # extract coordinates\r# create vertex sequence\rverts \u0026lt;- data.frame(x = V(flights)$longitude, y = V(flights)$latitude)  Supporting data To make our output a little more aesthetically pleasing, we will go ahead and transform the data to use Albers Equal Area Conic.\nstates \u0026lt;- tigris::states(cb = TRUE, progress_bar = FALSE) %\u0026gt;% filter(STUSPS %in% state.abb,\r!NAME %in% c(\u0026quot;Alaska\u0026quot;,\r\u0026quot;Hawaii\u0026quot;)) %\u0026gt;% sf::st_transform(crs = \u0026quot; +proj=aea +lat_1=20 +lat_2=60 +lat_0=40 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m no_defs\u0026quot;)\r coords_full \u0026lt;- cbind(V(flights)$longitude, V(flights)$latitude, V(flights)$name) # extract coordinates\rcoords_sf \u0026lt;- st_as_sf(x = as.data.frame(coords_full), coords = c(\u0026quot;V1\u0026quot;, \u0026quot;V2\u0026quot;), crs = 4326) %\u0026gt;% sf::st_transform(crs = \u0026quot; +proj=aea +lat_1=20 +lat_2=60 +lat_0=40 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m no_defs\u0026quot;)\r Edge bundle Create edge bundles\nforce_bundle \u0026lt;- edge_bundle_force(flights, xy = coords, compatibility_threshold = 0.6) force_bundle_sf \u0026lt;- force_bundle %\u0026gt;% st_as_sf(coords = c(\u0026quot;x\u0026quot;, \u0026quot;y\u0026quot;), crs = 4326) %\u0026gt;% sf::st_transform(crs = \u0026quot; +proj=aea +lat_1=20 +lat_2=60 +lat_0=40 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m no_defs\u0026quot;) %\u0026gt;% rowwise() %\u0026gt;% mutate(x_coord = st_coordinates(geometry)[[1]],\ry_coord = st_coordinates(geometry)[[2]])\r Create map source(\u0026quot;theme.R\u0026quot;)\r base_plot \u0026lt;- geom_sf(data = states,\rcolor = \u0026quot;white\u0026quot;,\rfill = NA,\rlwd = 0.1)  final_map \u0026lt;- ggplot() +\rbase_plot +\rgeom_path(data = force_bundle_sf,\raes(x = x_coord,\ry = y_coord,\rgroup = group),\rcolor = line_color,\rsize = 0.5,\ralpha = 0.2) +\rgeom_path(data = force_bundle_sf,\raes(x = x_coord,\ry = y_coord,\rgroup = group),\rcolor = \u0026quot;white\u0026quot;,\rsize = 0.005,\ralpha = 0.1) +\rgeom_sf(data = coords_sf,\rcolor = line_color,\rsize = 0.25) +\rgeom_sf(data = coords_sf,\rcolor = \u0026quot;white\u0026quot;,\rsize = 0.25,\ralpha = 0.1) +\rlabs(title = \u0026quot;US Flight Network\u0026quot;,\r# subtitle = \u0026quot;Force Bundle Method\u0026quot;,\rcaption = my_caption) +\rmy_theme\rfinal_map\r To get the sizing just right on the final image I posted on Twitter, I adjusted the size of my viewing panel in RStudio until I was happy with the dimensions.\nCredits This entire post was inspired by Dominic Royé.\nTrying a very nice new tool, thanks to {edgebundle} package created by @schochastics. Here the European flight network in a bundle flow version. #rstats #rspatial #datavis pic.twitter.com/dty4tTSYdE\n\u0026mdash; Dominic Royé (@dr_xeo) December 19, 2020  You can find my tweet with this map here.\n","date":1608336000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611524977,"objectID":"2e95c7c3010527be395a389204cdcc73","permalink":"lizroten.com/blog/maps-with-edgebundle/","publishdate":"2020-12-19T00:00:00Z","relpermalink":"lizroten.com/blog/maps-with-edgebundle/","section":"post","summary":"Replicating a snappy map","tags":["ggplot2","tidyverse","cartography"],"title":"Maps with {edgebundle}","type":"post"},{"authors":["Liz Roten","Ashley Asmus","Jonathan Ehrlich"],"categories":null,"content":"","date":1603843200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612038980,"objectID":"aba64a9dfbf06db6376b7be8e3065928","permalink":"lizroten.com/talk/ampo-covid-traffic/","publishdate":"2020-10-28T00:00:00Z","relpermalink":"lizroten.com/talk/ampo-covid-traffic/","section":"talk","summary":"To estimate public adherence to social distancing guidelines during the Coronavirus outbreak, we analyzed departures from “typical” traffic volumes on the metro freeway system of the Twin Cities region. A robust modeling approach, open-source code repository, and web-based dashboard for interacting with the data are assisting decision makers in Minnesota as they update social distancing guidelines and monitor economic recovery.","tags":["Metropolitan Council","COVID","Conference"],"title":"Monitoring public adherence to social distancing guidelines with traffic data","type":"talk"},{"authors":["Liz Roten","Mauricio Leon","Catherine Manzo"],"categories":null,"content":"","date":1603843200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612038980,"objectID":"832142d2ac0a1322d721f7a6c7cbe084","permalink":"lizroten.com/talk/ampo-streetlight-ghg/","publishdate":"2020-10-28T00:00:00Z","relpermalink":"lizroten.com/talk/ampo-streetlight-ghg/","section":"talk","summary":"It’s one thing to know that transportation is a significant cause of greenhouse gas emissions — it’s another to quantify how much. To address the scarcity of transportation emissions data in Minnesota, the Metropolitan Council of the Twin Cities has developed greenhouse gas emission estimates for transportation and land for cities, townships, and counties of the Twin Cities Metropolitan Region. This session will demonstrate how to leverage big data to centralize this type of research, save public funding, and enable communities to focus their efforts on implementing strategies to become more sustainable.","tags":["Metropolitan Council","StreetLight Data","Climate","Conference"],"title":"Using location-based services data for calculating the transportation greenhouse gas emissions of communities in Minnesota's Metropolitan Region","type":"talk"},{"authors":null,"categories":null,"content":"Twin Cities Rent Trends is a dashboard for analyzing rental housing market trends in the seven-county Twin Cities region. Rent data can be difficult and costly to obtain, and different sources can yield significantly different values. This app allows users to compare each source and view the data at different geographic levels. Users can view rent trends, including absolute rent price, rents adjusted for inflation, and year-over-year percent change. Users can also visualize the relationship between rent and vacancy rates (not available for all data sources).\nI built the app based on the {golem} framework, which builds the app repository as an R package. The result is a robust Shiny app, complete with testing and modular elements. The app integrates other package I\u0026rsquo;ve developed, including {council.skeleton} and {councilR}.\nScreenshots St. Paul rent and vacancy\nLynnhurst neighborhood rent\nData download page\n","date":1603411200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611525024,"objectID":"3e4b956d59dce16e4e458c06e545a98b","permalink":"lizroten.com/project/twin-cities-rent-trends/","publishdate":"2020-10-23T00:00:00Z","relpermalink":"lizroten.com/project/twin-cities-rent-trends/","section":"project","summary":"Visualize rent and vacancy trends for cities, townships, and neighborhoods in the Twin Cities","tags":["Metropolitan Council","Housing","Shiny"],"title":"Twin Cities Rent Trends","type":"project"},{"authors":null,"categories":null,"content":"I developed a methodology for estimating greenhouse gas emissions from passenger and commercial vehicles for every city or township in the Twin Cities region. Data implemented include aggregated, anonymized location-based services data provided by StreetLight Data, the Environmental Protection Agency\u0026rsquo;s MOVES model, and MnDOT\u0026rsquo;s vehicle classification data. The resulting data is implemented in the Council\u0026rsquo;s larger greenhouse gas inventory, which quantifies emissions from sources including energy, transportation, agriculture, and waste management.\nThe data is also available in our interactive tool, Twin Cities Greenhouse Gas Inventory\nYou can find more information on the Council\u0026rsquo;s website here.\n Climate change is occurring all around the world, including right here in the Twin Cities region. Minnesota has already experienced more extreme rainfall and warmer winters due to climate change, and more changes are on the way. The good news is that local jurisdictions can take meaningful action now to address climate change.\n  The climate is changing due to human activities which release greenhouse gases (GHGs) into the atmosphere and cause average temperatures to rise. Many human activities emit carbon dioxide, as well as even more powerful greenhouse gases like methane, nitrous oxide, and others. Each of these gases exist naturally in the environment, but human-built systems for energy, transportation, agriculture, and waste management are responsible for releasing climate-altering quantities of these gases.\n ","date":1594857600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611525024,"objectID":"9c68b12ce78996d73c1d770300dc0d2e","permalink":"lizroten.com/project/greenhouse-gas-inventory/","publishdate":"2020-07-16T00:00:00Z","relpermalink":"lizroten.com/project/greenhouse-gas-inventory/","section":"project","summary":"Estimating commercial and personal vehicle emissions with location-based services data","tags":["Metropolitan Council","StreetLight Data"],"title":"Greenhouse Gas Emissions Inventory","type":"project"},{"authors":null,"categories":null,"content":"In early 2020, the transportation and modeling team at the Metropolitan Council began using traffic data from the Minnesota Department of Transportation (MnDOT) to evaluate the impact of recent physical distancing efforts on regional and statewide travel. I developed an accompanying R Shiny app with sections for visualizing the model results, downloading tabular data, and explaining the model. Individual items include an interactive plot showing the percent difference from expected traffic levels and an interactive map displaying the change in expected traffic at individual traffic sensors across the Twin Cities metro area and Rochester area.\nI built the app based on the {golem} framework, which builds the app repository as an R package. The result is a robust Shiny app, complete with testing and modularized elements. The app integrates other package I\u0026rsquo;ve developed, including {council.skeleton} and {councilR}. The first iteration of the app was published within a week of starting on it.\nScreenshots The plot shows the daily relative decrease in freeway travel over time across the Twin Cities metropolitan region after March 1. Points that fall below the zero-line represent decreases in travel relative to typical travel on that day of the year and day of the week. Typical travel is estimated using a statistical analysis of traffic volumes from 2018, 2019, and 2020 prior to March 1.\nThe map shows the decreases in travel at individual traffic monitoring sites across the Twin Cities Metropolitan area. Traffic monitoring is performed by the Minnesota Department of Transportation (MnDOT) using detectors built into the infrastructure of the roads. These detectors are usually used to estimate congestion along Metro area highways.\nRelevent links Official news release\nLive app site (updated regularly)\nGitHub repository\n","date":1590105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611525024,"objectID":"fffbb588bb3759de8e951f67af8b75a8","permalink":"lizroten.com/project/covid-traffic-trends/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"lizroten.com/project/covid-traffic-trends/","section":"project","summary":"Monitoring social distance guideline adherence with traffic data","tags":["Metropolitan Council","Shiny"],"title":"COVID Traffic Trends","type":"project"},{"authors":[],"categories":["blog","tutorial"],"content":"\r\r\rI am a knitter. Knitting is a calming, fulfilling practice that keep my hands busy and require just enough brain power to keep my mind from wandering too far. Over the past winter, I conquered my fear of making socks, and now I profess that I am a sock knitter. I made socks for Christmas gifts, and churned out four pairs during my evenings, bus commutes, long work meetings, lectures, coffee and tea shop visits (basically everywhere). I’m comfortable with the standard stockinette sock, and I even ventured out into other patterns from Ravelry (the social medium for yarn folks), like Hermione’s Everyday Socks and the Slip It Simple Socks.\nBut, even as the weather is warming here in Minnesota, working from home means that I don’t have a commute and COVID-19 means that I have plenty of spare angst, so I’ve decided to make a new pair of socks, and work with a new pattern.\nAnd, just when I was starting to glaze over scrolling through endless Ravelry pages and reviews, I found ravelRy, an R package that interfaces seamlessly with Ravelry’s API. And its even on CRAN!\nLets install, and get going!\ninstall.packages(\u0026quot;ravelRy\u0026quot;)\rlibrary(ravelRy)\rlibrary(tidyverse)\rAuthentication\rAs with most APIs, you need to authenticate somehow. I’ll use my Ravelry account credentials (you’ll need a free, pro account to access the API).\nravelRy::ravelry_auth(key = \u0026quot;username\u0026quot;)\rravelRy::ravelry_auth(key = \u0026quot;password\u0026quot;)\r\rSearch for a sock pattern!\rLets start simple, and just look for the first 20 results for “sock” that are available as a Ravelry download.\nsearch_result \u0026lt;- search_patterns(\rquery = \u0026quot;sock\u0026quot;,\rpage_size = 20,\rcraft = \u0026quot;knitting\u0026quot;, # knitting or crochet\rfit = \u0026quot;adult\u0026quot;, # adult, baby, etc.\rravelry_download = TRUE\r)\rhead(search_result)\r#\u0026gt; # A tibble: 6 x 7\r#\u0026gt; free id name permalink designer.id designer.name pattern_sources\r#\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; #\u0026gt; 1 TRUE 891114 Rye Light rye-light 45502 tincanknits \u0026lt;df[,59] [3 x ~\r#\u0026gt; 2 TRUE 130787 Hermione~ hermiones-~ 14789 Erica Lueder \u0026lt;df[,59] [2 x ~\r#\u0026gt; 3 TRUE 1009293 Wohin? wohin 17216 Caoua Coffee \u0026lt;df[,59] [2 x ~\r#\u0026gt; 4 TRUE 580119 Rose Cit~ rose-city-~ 82613 Mara Catherin~ \u0026lt;df[,59] [1 x ~\r#\u0026gt; 5 FALSE 927223 Love Note love-note 45502 tincanknits \u0026lt;df[,59] [2 x ~\r#\u0026gt; 6 FALSE 1020039 Braidalot braidalot 97793 Dots Dabbles \u0026lt;df[,59] [2 x ~\rThe fourth result is even my old friend, “Hermione’s Everyday Socks!”\nsearch_result[4, ] # get the fourth row in the table\r#\u0026gt; # A tibble: 1 x 7\r#\u0026gt; free id name permalink designer.id designer.name pattern_sources\r#\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; #\u0026gt; 1 TRUE 580119 Rose Cit~ rose-city-~ 82613 Mara Catherine~ \u0026lt;df[,59] [1 x ~\rLets take a look at the actual pattern from the search results using get_patterns().\nhermione \u0026lt;- get_patterns(ids = search_result[4, ]$id)\rstr(hermione, max.level = 2)\r#\u0026gt; tibble [1 x 50] (S3: tbl_df/tbl/data.frame)\r#\u0026gt; $ comments_count : int 76\r#\u0026gt; $ created_at : chr \u0026quot;2015/05/16 13:27:58 -0400\u0026quot;\r#\u0026gt; $ currency : chr \u0026quot;\u0026quot;\r#\u0026gt; $ difficulty_average : num 2.15\r#\u0026gt; $ difficulty_count : int 2460\r#\u0026gt; $ downloadable : logi TRUE\r#\u0026gt; $ favorites_count : int 24978\r#\u0026gt; $ free : logi TRUE\r#\u0026gt; $ gauge : num 32\r#\u0026gt; $ gauge_divisor : int 4\r#\u0026gt; $ gauge_pattern : chr \u0026quot;Stockinette stitch in the round\u0026quot;\r#\u0026gt; $ generally_available : chr \u0026quot;2015/05/01 00:00:00 -0400\u0026quot;\r#\u0026gt; $ id : int 580119\r#\u0026gt; $ name : chr \u0026quot;Rose City Rollers\u0026quot;\r#\u0026gt; $ pdf_url : chr \u0026quot;\u0026quot;\r#\u0026gt; $ permalink : chr \u0026quot;rose-city-rollers\u0026quot;\r#\u0026gt; $ price : chr \u0026quot;\u0026quot;\r#\u0026gt; $ projects_count : int 12594\r#\u0026gt; $ published : chr \u0026quot;2015/05/01\u0026quot;\r#\u0026gt; $ queued_projects_count : int 4398\r#\u0026gt; $ rating_average : num 4.8\r#\u0026gt; $ rating_count : int 2605\r#\u0026gt; $ row_gauge : num 40\r#\u0026gt; $ updated_at : chr \u0026quot;2015/07/28 18:30:11 -0400\u0026quot;\r#\u0026gt; $ url : chr \u0026quot;\u0026quot;\r#\u0026gt; $ yardage : int 200\r#\u0026gt; $ yardage_max : int 350\r#\u0026gt; $ personal_attributes : chr \u0026quot;\u0026quot;\r#\u0026gt; $ sizes_available : chr \u0026quot;S, M, L\u0026quot;\r#\u0026gt; $ product_id : int 273690\r#\u0026gt; $ currency_symbol : chr \u0026quot;\u0026quot;\r#\u0026gt; $ ravelry_download : logi TRUE\r#\u0026gt; $ download_location :List of 1\r#\u0026gt; $ pdf_in_library : logi FALSE\r#\u0026gt; $ volumes_in_library : chr \u0026quot;\u0026quot;\r#\u0026gt; $ gauge_description : chr \u0026quot;32 stitches and 40 rows = 4 inches in Stockinette stitch in the round\u0026quot;\r#\u0026gt; $ yarn_weight_description: chr \u0026quot;Fingering (14 wpi)\u0026quot;\r#\u0026gt; $ yardage_description : chr \u0026quot;200 - 350 yards\u0026quot;\r#\u0026gt; $ pattern_needle_sizes :List of 1\r#\u0026gt; $ notes_html : chr \u0026quot;\\n\u0026lt;p\u0026gt;Easy, roll-top ankle socks perfect for summer knitting and wearing. These socks are knit from the top down\u0026quot;| __truncated__\r#\u0026gt; $ notes : chr \u0026quot;Easy, roll-top ankle socks perfect for summer knitting and wearing. These socks are knit from the top down, wit\u0026quot;| __truncated__\r#\u0026gt; $ packs :List of 1\r#\u0026gt; $ printings :List of 1\r#\u0026gt; $ yarn_weight :List of 1\r#\u0026gt; $ craft :List of 1\r#\u0026gt; $ pattern_categories :List of 1\r#\u0026gt; $ pattern_attributes :List of 1\r#\u0026gt; $ pattern_author :List of 1\r#\u0026gt; $ photos :List of 1\r#\u0026gt; $ pattern_type :List of 1\rstr(hermione$pattern_attributes)\r#\u0026gt; List of 1\r#\u0026gt; $ : tibble [7 x 2] (S3: tbl_df/tbl/data.frame)\r#\u0026gt; ..$ id : int [1:7] 3 10 23 26 200 286 300\r#\u0026gt; ..$ permalink: chr [1:7] \u0026quot;unisex\u0026quot; \u0026quot;adult\u0026quot; \u0026quot;top-cuff-down\u0026quot; \u0026quot;heel-flap\u0026quot; ...\rI thought the Hermione sock was fairly straightforward. What is the average difficulty, on a scale of 1 to 10?\nhermione$difficulty_count # how many reviews rated a difficulty?\r#\u0026gt; [1] 2460\rhermione$difficulty_average # what is the average difficulty?\r#\u0026gt; [1] 2.149187\rLets find my other sock pattern, Slip It Simple, and see what the difficulty rating is.\nslip_it_search \u0026lt;- search_patterns(query = \u0026quot;slip it simple sock\u0026quot;)\rNext, take the id column and feed it into get_patterns().\nslip_it \u0026lt;- get_patterns(ids = slip_it_search$id)\rWhat is our difficulty?\nslip_it$difficulty_count\r#\u0026gt; [1] 68\rslip_it$difficulty_average\r#\u0026gt; [1] 2\rThere are fewer reviews, but the difficulty is super low.\n\rRefining our search\rWe can use the pattern table for hermione and slip_it to narrow our search further.\nhead(search_patterns(\rquery = \u0026quot;sock\u0026quot;,\rpage_size = 20,\rcraft = \u0026quot;knitting\u0026quot;, # knitting or crochet\rfit = \u0026quot;adult\u0026quot;, # adult, baby, etc.\rravelry_download = TRUE,\rpattern_needle_sizes = 1,\rweight = \u0026quot;fingering\u0026quot;, # yarn weight\rtype = \u0026quot;sock\u0026quot;,\rcolors = 1\r))\r...\r#\u0026gt; # A tibble: 6 x 7\r#\u0026gt; free id name permalink designer.id designer.name pattern_sources\r#\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; #\u0026gt; 1 TRUE 891114 Rye Light rye-light 45502 tincanknits \u0026lt;df[,59] [3 x ~\r#\u0026gt; 2 TRUE 130787 Hermione~ hermiones-~ 14789 Erica Lueder \u0026lt;df[,59] [2 x ~\r#\u0026gt; 3 TRUE 580119 Rose Cit~ rose-city-~ 82613 Mara Catherin~ \u0026lt;df[,59] [1 x ~\r#\u0026gt; 4 TRUE 315418 Vanilla ~ vanilla-la~ 53376 Virginia Rose~ \u0026lt;df[,59] [1 x ~\r#\u0026gt; 5 FALSE 720294 Mina\u0026#39;s V~ minas-vani~ 81846 Knitting Expa~ \u0026lt;df[,59] [2 x ~\r...\rAnother trick is to go look at the URL when I am searching on Ravelry itself. This gives me an idea of what search terms I can add to search_patterns().\nrefined_search \u0026lt;- search_patterns(\rquery = \u0026quot;socks\u0026quot;,\rpc = \u0026quot;mid-calf\u0026quot;,\rpage_size = 100,\rcraft = \u0026quot;knitting\u0026quot;, # knitting or crochet\r# fit = \u0026quot;adult\u0026quot;, # adult, baby, etc.\rravelry_download = TRUE,\rpattern_needle_sizes = 1,\rweight = \u0026quot;fingering\u0026quot;, # yarn weight\rtype = \u0026quot;sock\u0026quot;,\rcolors = 1,\rdiff = \u0026quot;3.5%7C8\u0026quot;,\rlanguage = \u0026quot;en\u0026quot;,\rsort = \u0026quot;projects\u0026quot;,\rphoto = \u0026quot;yes\u0026quot;\r)\r\rReview refined search results\rNow that I’ve picked out 100 patterns to consider/make fun plots with, lets review them in more detail.\nrefined_patterns \u0026lt;- get_patterns(ids = refined_search$id) # this might take a while\rTo start plotting, I will import my theme and {dutchmasters}.\nsource(\u0026quot;my_sock_theme.R\u0026quot;)\rlibrary(dutchmasters)\rggplot() +\rgeom_density(refined_patterns,\rmapping = aes(\rx = comments_count,\rfill = free\r),\ralpha = 0.7,\rcolor = \u0026quot;gray\u0026quot;\r) +\rdutchmasters::scale_fill_dutchmasters(palette = \u0026quot;pearl_earring\u0026quot;) +\rlabs(\rtitle = \u0026quot;Pattern Comment Density\u0026quot;,\rx = \u0026quot;Comment count\u0026quot;,\ry = \u0026quot;Density\u0026quot;,\rcaption = my_caption\r) +\rmy_theme()\rNext, we’ll make a density plot series comparing the average difficulty rating for each pattern attribute (check out this example for this plot’s inspiration).\npattern_details_attributes \u0026lt;- refined_patterns %\u0026gt;%\runnest(cols = \u0026quot;pattern_attributes\u0026quot;, names_sep = \u0026quot;_\u0026quot;)\rtop_attributes \u0026lt;- pattern_details_attributes %\u0026gt;%\rfilter(difficulty_count \u0026gt;= 20) %\u0026gt;%\rcount(pattern_attributes_permalink) %\u0026gt;%\rfilter(n \u0026gt;= 20)\rattributes_long \u0026lt;- pattern_details_attributes %\u0026gt;%\rfilter(pattern_attributes_permalink %in% top_attributes$pattern_attributes_permalink) %\u0026gt;%\rmutate(pattern_attributes_permalink = stringr::str_to_title(pattern_attributes_permalink)) %\u0026gt;% select(id, pattern_attributes_permalink, difficulty_average, rating_average)\rplot_diff_by_att \u0026lt;- attributes_long %\u0026gt;%\rggplot() +\rgeom_density(aes(x = difficulty_average),\rfill = dutchmasters::dutchmasters$pearl_earring[4],\rcolor = \u0026quot;gray\u0026quot;,\routline.type = \u0026quot;full\u0026quot;\r) +\rfacet_grid(reorder(\rpattern_attributes_permalink,\rdifficulty_average, median\r) ~ .,\rswitch = \u0026quot;y\u0026quot;, scales = \u0026quot;free_y\u0026quot;\r) +\rscale_x_continuous(limits = c(2, 7)) +\rlabs(\rtitle = \u0026quot;Average difficulty rating by pattern attribute\u0026quot;,\r# subtitle = \u0026quot;Sock knitting patterns\u0026quot;,\ry = \u0026quot;\u0026quot;, x = \u0026quot;Average difficulty\u0026quot;,\rcaption = my_caption\r) +\rmy_theme() +\rtheme(\rpanel.spacing.y = unit(0, \u0026quot;lines\u0026quot;),\rpanel.grid = element_blank(),\rpanel.grid.major.y = element_blank(),\rstrip.text.y.left = element_text(angle = 0),\rstrip.background = element_rect(fill = NA, color = NA),\raxis.text.y = element_blank())\rplot_diff_by_att\r\rNarrow down results\rI want to use a pattern with high ratings and a high number of projects. What do these distributions look like?\nlibrary(cowplot)\rproject_count \u0026lt;- ggplot(data = refined_patterns) +\rgeom_density(\rmapping = aes(x = projects_count),\rfill = dutchmasters::dutchmasters$pearl_earring[2],\ralpha = 0.8,\rcolor = \u0026quot;gray\u0026quot;\r) +\rscale_x_continuous(labels = scales::comma) +\rlabs(\rtitle = \u0026quot;Project Count\u0026quot;,\rx = \u0026quot;Projects\u0026quot;,\ry = \u0026quot;\u0026quot;\r) +\rmy_theme()\rrating_count \u0026lt;- ggplot(data = refined_patterns) +\rgeom_density(\rmapping = aes(x = rating_count),\rfill = dutchmasters::dutchmasters$pearl_earring[3],\ralpha = 0.8,\rcolor = \u0026quot;gray\u0026quot;\r) +\rscale_x_continuous(labels = scales::comma) +\rlabs(\rtitle = \u0026quot;Rating Count\u0026quot;,\rx = \u0026quot;Ratings\u0026quot;,\ry = \u0026quot;\u0026quot;,\rcaption = my_caption\r) +\rmy_theme()\rcowplot::plot_grid(project_count, rating_count)\rIt looks like there is a big drop-off around 1,000 project and 500 ratings.\nproject_rating_patterns \u0026lt;- refined_patterns %\u0026gt;%\rfilter(\rprojects_count \u0026gt;= 1000,\rrating_count \u0026gt;= 500\r)\rThat filter() took us from 100 patterns to 11. Progress!\nNow, lets look at the ratings and difficulty. We will also separate these out by availability.\nggplot(project_rating_patterns) +\rgeom_point(\rmapping = aes(\rx = difficulty_average,\ry = rating_average,\rcolor = free\r),\rsize = 4\r) +\rdutchmasters::scale_color_dutchmasters(palette = \u0026quot;pearl_earring\u0026quot;) +\rlabs(\rtitle = \u0026quot;Average Rating and Average Difficulty\u0026quot;,\rx = \u0026quot;Average difficulty\u0026quot;,\ry = \u0026quot;Average Rating\u0026quot;,\rcaption = my_caption\r) +\rmy_theme()\rNothing too informative here. What are the top pattern attributes?\nproject_rating_patterns %\u0026gt;%\runnest(cols = \u0026quot;pattern_attributes\u0026quot;, names_sep = \u0026quot;_\u0026quot;) %\u0026gt;%\rcount(pattern_attributes_permalink) %\u0026gt;%\rfilter(n \u0026gt; 5) %\u0026gt;%\rarrange(desc(n)) %\u0026gt;%\rggplot() +\rgeom_col(aes(\rx = pattern_attributes_permalink,\ry = n\r),\rfill = dutchmasters::dutchmasters$pearl_earring[9]\r) +\rlabs(\rtitle = \u0026quot;Top pattern attributes\u0026quot;,\rx = \u0026quot;Pattern attribute\u0026quot;,\ry = \u0026quot;\u0026quot;,\rcaption = my_caption\r) +\rmy_theme()\rAnother thing that makes patterns easy to follow is if they are downloadable (as opposed to linked to another web page). Lets filter() for that, and have a difficulty at least above 4.\nfilter(\rproject_rating_patterns, downloadable == TRUE,\rdifficulty_average \u0026gt;= 4\r) %\u0026gt;%\rarrange(-rating_average)\r...\r#\u0026gt; comments_count created_at currency difficulty_average\r#\u0026gt; 1 8 2010/10/25 09:23:15 -0400 USD 4.252446\r#\u0026gt; 2 27 2007/01/12 00:51:53 -0500 USD 4.903895\r#\u0026gt; 3 131 2010/02/11 12:07:46 -0500 4.434030\r#\u0026gt; 4 22 2007/09/07 11:54:33 -0400 4.520376\r#\u0026gt; difficulty_count downloadable favorites_count free gauge gauge_divisor\r#\u0026gt; 1 511 TRUE 4027 FALSE 32 4\r#\u0026gt; 2 2362 TRUE 11155 TRUE 8 1\r...\r\rFetch images\rNow that we only have four left, lets fetch the images!\nphoto_links \u0026lt;- filter(\rproject_rating_patterns, downloadable == TRUE,\rdifficulty_average \u0026gt;= 4\r) %\u0026gt;%\runnest(cols = photos, names_sep = \u0026quot;_\u0026quot;) %\u0026gt;%\rfilter(photos_sort_order == 4) %\u0026gt;%\rselect(id, name, photos_medium_url)\rNext, we will use {imager} to fetch the data and plot it.\nlibrary(imager)\rphoto_links$name\r#\u0026gt; [1] \u0026quot;Pointelle\u0026quot; \u0026quot;Firestarter\u0026quot; \u0026quot;Pomatomus\u0026quot; \u0026quot;Skew\u0026quot;\rmap(photo_links$photos_medium_url, load.image) %\u0026gt;%\rmap(plot, axes = FALSE)\r#\u0026gt; [[1]]\r#\u0026gt; Image. Width: 425 pix Height: 500 pix Depth: 1 Colour channels: 3 #\u0026gt; #\u0026gt; [[2]]\r#\u0026gt; Image. Width: 500 pix Height: 381 pix Depth: 1 Colour channels: 3 #\u0026gt; #\u0026gt; [[3]]\r#\u0026gt; Image. Width: 500 pix Height: 500 pix Depth: 1 Colour channels: 3 #\u0026gt; #\u0026gt; [[4]]\r#\u0026gt; Image. Width: 348 pix Height: 500 pix Depth: 1 Colour channels: 3\r\rAnd the winner is….\rPomatomus! I mean, look at those gorgeous waves!\nPomatomus socks from the front\n\rI have a lovely merino/nylon blend by Sun Valley Fibers waiting for me. I hope you enjoyed this little journey!\n\rCredits\rI followed along this example by the ravelRy package author, Kaylin Pavlik. I used colors from Edwin Thoen’s R package, dutchmasters.\n\r","date":1586304000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611524977,"objectID":"491c2dd92b076459a4921de770ec7a79","permalink":"lizroten.com/blog/finding-the-perfect-sock-pattern-with-ravelry/","publishdate":"2020-04-08T00:00:00Z","relpermalink":"lizroten.com/blog/finding-the-perfect-sock-pattern-with-ravelry/","section":"post","summary":"Using Ravelry's API to find just the right sock pattern","tags":["tidyverse","ggplot2","ravelry"],"title":"Finding the perfect sock pattern with {ravelRy}","type":"post"},{"authors":[],"categories":["tutorial"],"content":"\r\r\r\r\rSince I got back from #rstudioconf, I’ve started to warm up to the idea of sharing my code, even if it isn’t perfect. There may be typos, the blog post may be short, but sharing my work is beneficial for the greater #rstats community, and supports open-source data science.\nSo this belated post is inspired by Cities Start to Question an American Ideal: A House With a Yard on Every Lot, in which the NY Times examines residential zoning patterns in different cities. Residential areas are split into two categories, single-family detached homes and all other housing such as townhomes, duplexes, and apartments. This is especially relevant given the current housing shortage across the US.\nImport data First, lets import our packages.\n# spatial packages library(sf)\rlibrary(geojsonsf)\rlibrary(rgdal)\rlibrary(lwgeom)\r# data cleaning\rlibrary(dplyr)\rlibrary(janitor)\rlibrary(fuzzyjoin)\rlibrary(stringr)\r# plotting\rlibrary(ggplot2)\rlibrary(showtext)\rlibrary(DT)\r Next, lets import our data. read_sf() is super useful here, because it will read in an sf object from a link to the spatial file we want. In this case, the link comes from each city’s open data portal\nWhen you go to the data portal and find the dataset you want, right click the link to download the GeoJSON and copy the link. Then, paste it into read_sf() and you’re good to go! Say goodbye to massive data folders!\nFor this post, I’ve chosen (somewhat randomly) Pittsburgh, PA, Austin, TX, and Boston, MA.\npitts \u0026lt;- read_sf(\u0026quot;http://pghgis-pittsburghpa.opendata.arcgis.com/datasets/e67592c2904b497b83ccf876fced7979_0.geojson\u0026quot;)\rboston \u0026lt;- read_sf(\u0026quot;http://bostonopendata-boston.opendata.arcgis.com/datasets/b601516d0af44d1c9c7695571a7dca80_0.geojson?outSR={%22latestWkid%22:2249,%22wkid%22:102686}\u0026quot;)\raustin \u0026lt;- read_sf(\u0026quot;https://data.austintexas.gov/api/geospatial/5rzy-nm5e?method=export\u0026amp;format=GeoJSON\u0026quot;)\r Here is the styling I’m using on the maps.\nshowtext_auto()\rfont_add(\u0026quot;Lato\u0026quot;, \u0026quot;Lato-Regular.ttf\u0026quot;)\rfont_add(\u0026quot;Open Sans Light\u0026quot;, \u0026quot;OpenSans-Light.ttf\u0026quot;)\rfont_add(\u0026quot;PT Sans\u0026quot;, \u0026quot;PTSans-Regular.ttf\u0026quot;)\rfont_add(\u0026quot;PT Serif\u0026quot;, \u0026quot;PTSerif-Regular.ttf\u0026quot;)\r## font sizes --------------------------------------------\rsize_header \u0026lt;- 14*3.4\rsize_subtitle \u0026lt;- 12*3.4\rsize_axis_title \u0026lt;- 12*3.4\rsize_legend_title \u0026lt;- 12*3.4\rsize_axis_text \u0026lt;- 8*3.4\rsize_legend_text \u0026lt;- 8*3.4\rsize_caption \u0026lt;- 6*3.4\r## color -------------------------------------------------\rbackground_color \u0026lt;- \u0026quot;#ffffff\u0026quot;\rblue \u0026lt;- \u0026quot;#66b2a9\u0026quot;\rpink \u0026lt;- \u0026quot;#dd2292\u0026quot;\rmy_colors \u0026lt;- c(\r\u0026quot;#9BABBF\u0026quot;,\r\u0026quot;#8C694A\u0026quot;,\r\u0026quot;#6C733C\u0026quot;,\r\u0026quot;#D9B991\u0026quot;\r)\r## theme function -----------------------------------------\rmy_theme \u0026lt;- function(...) {\rtheme_void() +\rtheme(\r### plot and panel-----------------------------------\rplot.background = element_rect(\rfill = background_color,\rlinetype = 0,\rcolour = NA\r),\rpanel.background = element_rect(\rfill = background_color,\rlinetype = 0,\rcolor = NA\r),\rpanel.grid = element_blank(),\rplot.margin = margin(rep(10, 4), unit = \u0026quot;pt\u0026quot;),\rpanel.border = element_blank(),\r### title and caption -------------------------------\rtitle = element_text(family = \u0026quot;PT Serif\u0026quot;,\rsize = size_header),\rplot.caption = element_text(size = size_caption),\r# plot.caption.position = \u0026quot;plot\u0026quot;,\r### axis and strip text ------------------------------\rstrip.text = element_blank(),\raxis.title = element_text(size = size_axis_title),\raxis.text = element_blank(),\r## legend text ----------------------------------------\rlegend.text = element_text(\rfamily = \u0026quot;Open Sans Light\u0026quot;,\rsize = size_legend_text\r)\r# legend.position = \u0026quot;bottom\u0026quot;\r)\r}\r Pittsburgh So, what are our column names?\nnames(pitts)\r ## [1] \u0026quot;objectid\u0026quot; \u0026quot;area\u0026quot; \u0026quot;perimeter\u0026quot; \u0026quot;zoning_\u0026quot; ## [5] \u0026quot;zoning_id\u0026quot; \u0026quot;zon_new\u0026quot; \u0026quot;shape_leng\u0026quot; \u0026quot;correctionlabel\u0026quot; ## [9] \u0026quot;full_zoning_type\u0026quot; \u0026quot;legendtype\u0026quot; \u0026quot;municode\u0026quot; \u0026quot;status\u0026quot; ## [13] \u0026quot;created_user\u0026quot; \u0026quot;created_date\u0026quot; \u0026quot;last_edited_user\u0026quot; \u0026quot;last_edited_date\u0026quot;\r## [17] \u0026quot;Shape__Area\u0026quot; \u0026quot;Shape__Length\u0026quot; \u0026quot;geometry\u0026quot;\r We are most interested in the “legendtype” column.\nunique(pitts$legendtype)\r ## [1] \u0026quot;Parks\u0026quot; \u0026quot;Local Neighborhood Commercial \u0026quot; ## [3] \u0026quot;Highway Commercial\u0026quot; \u0026quot;Single-Unit Detached Residential\u0026quot;\r## [5] \u0026quot;Urban Industrial\u0026quot; \u0026quot;Planned Unit Development\u0026quot; ## [7] \u0026quot;Neighborhood Industrial\u0026quot; \u0026quot;Two-Unit Residential\u0026quot; ## [9] \u0026quot;Multi-Unit Residential\u0026quot; \u0026quot;Hillside \u0026quot; ## [11] \u0026quot;Single-Unit Attached Residential\u0026quot; \u0026quot;Mount Oliver Borough\u0026quot; ## [13] \u0026quot;Three-Unit Residential\u0026quot; \u0026quot;General Industrial \u0026quot; ## [15] \u0026quot;Oakland Public Realm\u0026quot; \u0026quot;Specially Planned\u0026quot; ## [17] \u0026quot;Golden Triangle \u0026quot; \u0026quot;Neighborhood Office\u0026quot; ## [19] \u0026quot;Educational/Medical Institution\u0026quot; \u0026quot;Urban Neighborhood Commercial\u0026quot; ## [21] \u0026quot;Grandview Public Realm\u0026quot; \u0026quot;Uptown Public Realm\u0026quot; ## [23] \u0026quot;Riverfront\u0026quot;\r These are useful descriptions! We will re-code them into three categories: single-family detached, not single-family detached, and non-residential.\npitts_clean \u0026lt;- pitts %\u0026gt;% rowwise() %\u0026gt;% mutate(zone_simple = if(legendtype %in% c(\u0026quot;Single-Unit Attached Residential\u0026quot;,\r\u0026quot;Two-Unit Residential\u0026quot;, \u0026quot;Three-Unit Residential\u0026quot;,\r\u0026quot;Multi-Unit Residential\u0026quot;)){\rzone_simple = \u0026quot;non_sfd\u0026quot;\r} else if (legendtype == \u0026quot;Single-Unit Detached Residential\u0026quot;){\rzone_simple = \u0026quot;sfd\u0026quot;\r} else {\rzone_simple = \u0026quot;non_res\u0026quot;\r}) %\u0026gt;% st_as_sf()\r Now for the map!\nFor the caption, we can take advantage of the “last_edited_date” column and automatically put in the correct date!\nggplot() +\rgeom_sf(data = pitts_clean,\raes(fill = zone_simple),\rcolor = \u0026quot;#C8C8C8\u0026quot;,\rsize = 0.2,\ralpha = 0.5) +\rlabs(title = \u0026quot;Pittsburgh\u0026quot;,\rsubtitle = \u0026quot;Residential zoning\u0026quot;,\rfill = \u0026quot;\u0026quot;,\rcaption = paste(\u0026quot;@LizRoten | City of Pittsburgh,\u0026quot;,\rlubridate::year(pitts_clean$last_edited_date))) + my_theme() +\rscale_fill_manual(values = c(\u0026quot;whitesmoke\u0026quot;, blue, pink),\rlabels = c(\u0026quot;Non-residential\u0026quot;,\r\u0026quot;Non-single family\u0026quot;,\r\u0026quot;Single family\u0026quot;))  This map looks like its missing something, so I’m going to add in hydrology features.\n# import \u0026quot;Allegheny County Hydrology Areas\u0026quot; pitt_water \u0026lt;- read_sf(\u0026quot;http://openac-alcogis.opendata.arcgis.com/datasets/9ff3941e47f74c609057cb60f4992852_0.geojson\u0026quot;) %\u0026gt;% sf::st_make_valid() %\u0026gt;% st_intersection(sf::st_make_valid(pitts)) # instersect with city limits\r ggplot() +\rgeom_sf(data = pitts_clean,\raes(fill = zone_simple),\rcolor = \u0026quot;#C8C8C8\u0026quot;,\rsize = 0.2,\ralpha = 0.5) +\rlabs(title = \u0026quot;Pittsburgh\u0026quot;,\rsubtitle = \u0026quot;Residential zoning\u0026quot;,\rfill = \u0026quot;\u0026quot;,\rcaption = paste(\u0026quot;@LizRoten | City of Pittsburgh,\u0026quot;,\rformat(pitts_clean$last_edited_date, \u0026quot;%Y\u0026quot;))) + my_theme() +\rscale_fill_manual(values = c(\u0026quot;whitesmoke\u0026quot;, blue, pink),\rlabels = c(\u0026quot;Non-residential\u0026quot;,\r\u0026quot;Non-single family\u0026quot;,\r\u0026quot;Single family\u0026quot;)) +\rgeom_sf(data = pitt_water,\rfill = \u0026quot;lightblue\u0026quot;, color = \u0026quot;NA\u0026quot;)\r Austin Lets look at the column names for Austin.\nnames(austin)\r ## [1] \u0026quot;created_by\u0026quot; \u0026quot;shape_area\u0026quot; \u0026quot;created_date\u0026quot; \u0026quot;zoning_ztype\u0026quot; ## [5] \u0026quot;objectid\u0026quot; \u0026quot;shape_length\u0026quot; \u0026quot;modified_by\u0026quot; \u0026quot;modified_date\u0026quot;\r## [9] \u0026quot;zoning_id\u0026quot; \u0026quot;geometry\u0026quot;\r Next, we can look at “zoning_ztype.”\nhead(unique(austin$zoning_ztype))\r ## [1] \u0026quot;SF-3-NCCD-NP\u0026quot; \u0026quot;MF-2\u0026quot; \u0026quot;RR\u0026quot; \u0026quot;SF-1\u0026quot; \u0026quot;MF-3-NP\u0026quot; ## [6] \u0026quot;SF-2\u0026quot;\r YIKES. Looks like we need a data dictionary.\nI would love to say that I elegantly extracted the zoning codes from the city’s website, but I ended up copying the HTML table to Excel and manipulating the columns from there. The text-to-columns tool is very useful fo instances like this. I also added codes “SF-4” and “MF,” which weren’t explicitly provided.\naustin_desc \u0026lt;- read.csv(\u0026quot;data/zoning_descriptions.csv\u0026quot;) %\u0026gt;% clean_names()\rDT::datatable(austin_desc, rownames = FALSE)\r \r{\"x\":{\"filter\":\"none\",\"data\":[[\"LA\",\"SF-4B\",\"MF-1\",\"MF-4\",\"MH\",\"MF-2\",\"GO\",\"GR\",\"DMU\",\"CS-1\",\"MI\",\"DR\",\"PUD\",\"NBG\",\"MF-5\",\"SF-6\",\"MF-3\",\"MF-6\",\"MF\",\"NO\",\"CR\",\"L\",\"W/LO\",\"CH\",\"LI\",\"AV\",\"P\",\"ERC\",\"SF-2\",\"RR\",\"SF-3\",\"SF-5\",\"SF-1\",\"SF-4\",\"LO\",\"LR\",\"CBD\",\"CS\",\"IP\",\"R\u0026amp;D\",\"AG\",\"TOD\",\"TND\",\"CO\",\"NCCD\",\"CVC\",\"PDA\",\"WO\",\"MU\",\"CURE\",\"CDZ\",\"CAZ\",\"PSZ\",\"DPZ\",\"DCZ\",\"SF-4A\"],[\"Lake Austin Residence \",\"Single Family Residence - Condominium \",\"Multi-Family Residence - Limited Density \",\"Multi-Family Residence - Moderate-High Density \",\"Mobile Home Residence \",\"Multi-Family Residence - Low Density \",\"General Office \",\"Community Commercial \",\"Downtown Mixed Use \",\"Commercial-Liquor Sales \",\"Major Industry \",\"Development Reserve \",\"Planned Unit Development \",\"North Burnet/Gateway District \",\"Multi-Family Residence - High Density \",\"Townhouse \u0026amp; Condominium Residence \",\"Multi-Family Residence - Medium Density \",\"Multi-Family Residence - Highest Density \",\"Multifamily Residence\",\"Neighborhood Office \",\"Commercial Recreation \",\"Lake Commercial \",\"Warehouse Limited Office \",\"Commercial Highway \",\"Limited Industrial Services \",\"Aviation Services \",\"Public \",\"East Riverside Corridor \",\"Single Family Residence - Standard Lot\",\"Rural Residence \",\"Family Residence \",\"Urban Family Residence \",\"Single Family Residence - Large Lot\",\"Single Family Residence\",\"Limited Office \",\"Neighborhood Commercial \",\"Central Business District \",\"General Commercial Services \",\"Industrial Park \",\"Research and Development \",\"Agricultural \",\"Transit-Oriented Development \",\"Traditional Neighborhood District \",\"Conditional overlay\",\"Neighborhood Conservation Combining District \",\"Capitol View Corridor Combining District \",\"Planned Development Area Combining District\",\"Waterfront Overlay Combining District\",\"Mixed Use\",\"Central Urban Redevelopment\",\"Capitol Dominance Combining District\",\"Congress Avenue Combining District\",\"Sixth/Pecan Street Combining District\",\"Downtown Parks Combining District\",\"Downtown Creeks Combining District\",\"Single Family Residence - Small Lot\"]],\"container\":\"\\n \\n \\n code\\n description\\n \\n \\n\",\"options\":{\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\rWe are going to break up Austin into two separate datasets: one with residential zones, and the other with non-residential zones.\nWe will join our spatial data with the code descriptions using “zoning_ztype,” then add a column for residential zoning type using str_detect().\naustin_w_desc \u0026lt;- left_join(austin, austin_desc,\rby = c(\u0026quot;zoning_ztype\u0026quot; = \u0026quot;code\u0026quot;))\raustin_coded \u0026lt;- austin_w_desc %\u0026gt;% group_by(objectid) %\u0026gt;% mutate(residence_zone = # detect key character sequences and add case_when(stringr::str_detect(zoning_ztype, \u0026quot;SF\u0026quot;) ~ \u0026quot;Single family\u0026quot;,\rstringr::str_detect(zoning_ztype, \u0026quot;MH\u0026quot;) ~ \u0026quot;Non-single family\u0026quot;,\rstringr::str_detect(zoning_ztype, \u0026quot;MF\u0026quot;) ~ \u0026quot;Non-single family\u0026quot;,\rstringr::str_detect(zoning_ztype, \u0026quot;LA\u0026quot;) ~ \u0026quot;Non-single family\u0026quot;,\rstringr::str_detect(zoning_ztype, \u0026quot;RR\u0026quot;) ~ \u0026quot;Non-single family\u0026quot;,\rTRUE ~ \u0026quot;Non-residential\u0026quot;))\r Now, lets map it! I adjusted the fill color for non-residential zones because the scale is much smaller than Pittsburgh.\nggplot() +\rgeom_sf(data = austin_coded,\rmapping = aes(fill = residence_zone),\rcolor = NA,\ralpha = 0.5) +\rscale_fill_manual(values = c(\u0026quot;snow3\u0026quot;, blue, pink),\rlabels = c(\u0026quot;Non-residential\u0026quot;,\r\u0026quot;Non-single family\u0026quot;,\r\u0026quot;Single family\u0026quot;)) +\rlabs(title = \u0026quot;Austin\u0026quot;,\rsubtitle = \u0026quot;Residential zoning\u0026quot;,\rfill = \u0026quot;\u0026quot;,\rcaption = paste(\u0026quot;@LizRoten | City of Austin,\u0026quot;,\rformat(austin_coded$modified_date, \u0026quot;%Y\u0026quot;))) +\rmy_theme()\r Boston Lets check our column names.\nnames(boston)  ## [1] \u0026quot;OBJECTID\u0026quot; \u0026quot;ZONE_\u0026quot; \u0026quot;DISTRICT\u0026quot; \u0026quot;MAPNO\u0026quot; ## [5] \u0026quot;ARTICLE\u0026quot; \u0026quot;SUBDISTRIC\u0026quot; \u0026quot;Unique_Code\u0026quot; \u0026quot;FAR\u0026quot; ## [9] \u0026quot;Shape_STArea__\u0026quot; \u0026quot;Shape_STLength__\u0026quot; \u0026quot;Zone_Desc\u0026quot; \u0026quot;geometry\u0026quot;\r And then the “Zone_Desc” column.\nhead(unique(boston$Zone_Desc))\r ## [1] \u0026quot;Community Commercial\u0026quot; \u0026quot;Waterfront Manufacturing\u0026quot; ## [3] \u0026quot;Restricted Manufacturing\u0026quot; \u0026quot;Neighborhood Development Area\u0026quot;\r## [5] \u0026quot;Local Industrial\u0026quot; \u0026quot;Waterfront Commercial\u0026quot;\r HA! Sweet, sweet human-readable descriptions!\nTo make things a little easier, we can break out the entire dataset into residential and non-residential groups, and then rbind() them back together.\nboston_res \u0026lt;- boston %\u0026gt;% filter(SUBDISTRIC == \u0026quot;Residential\u0026quot;) %\u0026gt;% rowwise() %\u0026gt;% mutate(category = if(Zone_Desc == \u0026quot;One-Family Residential\u0026quot;){\rcategory = \u0026quot;Single Family\u0026quot;\r} else {\rcategory = \u0026quot;Non-single family\u0026quot;\r}) %\u0026gt;% st_as_sf()\r Now create the non-residential and bind the two back together.\nboston_non_res \u0026lt;- boston %\u0026gt;% filter(SUBDISTRIC != \u0026quot;Residential\u0026quot;, SUBDISTRIC != \u0026quot;Open Space\u0026quot;, # remove primarily water features\rDISTRICT != \u0026quot;Boston Harbor\u0026quot;,\rDISTRICT != \u0026quot;Harborpark: Dorchester Bay/Neponset River Waterfront\u0026quot;) %\u0026gt;% mutate(category = \u0026quot;Non-residential\u0026quot;)\rboston_all \u0026lt;- rbind(boston_res, boston_non_res)\r Finally, map!\nggplot() +\rgeom_sf(data = boston_all,\rmapping = aes(fill = category),\rcolor = \u0026quot;#c8c8c8\u0026quot;,\rsize = 0.1, alpha = 0.5) +\rscale_fill_manual(values = c(\u0026quot;snow3\u0026quot;, blue, pink),\rlabels = c(\u0026quot;Non-residential\u0026quot;,\r\u0026quot;Non-single family\u0026quot;,\r\u0026quot;Single family\u0026quot;)) +\rlabs(title = \u0026quot;Boston\u0026quot;,\rsubtitle = \u0026quot;Residential zoning\u0026quot;,\rfill = \u0026quot;\u0026quot;,\rcaption = \u0026quot;@LizRoten | City of Boston, 2020\u0026quot;) +\rmy_theme()\r ","date":1581724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611524977,"objectID":"a4c8daae2ef2b19dc7cf8acce8352801","permalink":"lizroten.com/blog/housing-density-in-us-cities/","publishdate":"2020-02-15T00:00:00Z","relpermalink":"lizroten.com/blog/housing-density-in-us-cities/","section":"post","summary":"Since I got back from #rstudioconf, I’ve started to warm up to the idea of sharing my code, even if it isn’t perfect. There may be typos, the blog post may be short, but sharing my work is beneficial for the greater #rstats community, and supports open-source data science.","tags":["ggplot2","tutorial","spatial","maps","sf","R Markdown"],"title":"Housing Density in US Cities","type":"post"},{"authors":[],"categories":["tutorial"],"content":"\r\r\r\r\rBackground Those of us even mildly obsessed with maps will be familiar with Harold Fisk’s 1944 series documenting the historic travel of the Mississippi River in Mississippi River Alluvial Valley. In my house in college, filled with geography majors and map enthusiasts, we had a small print hung on the wall, and it was easy to start reading it, and end up standing there, just staring, for quite a while.\nEven viewing on a screen, its easy to see how you can get lost in the map. The colors are distinct and vivid, and the contextual information, like political boundaries and fault lines, against the aged sepia base do not distract. The map is dynamic, with irregular shapes and curves. If not done right, the messiness could overwhelm the viewer, but Fisk succeeds in capturing the audience’s attention. The content itself makes you reconsider your relationship with this body of water. Seeing how it has moved and changed course over time reminds you of how small, short and insignificant our lives can be compared to the Earth’s natural history.\nI adore this map. I won’t attempt to fully recreate it here, but I want to explore the data behind it, and see what I can find.\nPrep Lets load in packages I know I’ll need.\nlibrary(rgdal)\rlibrary(dplyr)\rlibrary(sf)\rlibrary(ggplot2)\rlibrary(leaflet)\rlibrary(xml2)\rlibrary(data.table)\rlibrary(raster)\rlibrary(ggrepel)\rlibrary(stringr)\rlibrary(ggmap)\rlibrary(tidycensus)\rlibrary(cowplot)\r To start, I studied the map and did an inventory of the elements.\n State lines Elevation Mississippi River Rivers other than the Mississippi County lines Cut offs (neck, chute, and fault) Lakes Major landmarks Flood areas Much more!  I was having difficulty working with raster elevation data, so I decided to save that for another day. However, there is a dataset from a 1994 study by Roger T. Saucier, “Geomorphology and Quaternary Geologic History of the Lower Mississippi Valley, Volumes I and II.” The United States Geological Survey (USGS) developed both georeferenced plates and vector shapefiles. I downloaded both the datasets from the USGS website.\nData cleaning I downloaded the zipped shapefile, so here I unzip the folder, read in the shapefile, and convert it to an sf object.\nunzip(\u0026quot;data/gis/Saucier_Geomorph_shapefile.zip\u0026quot;, exdir = \u0026quot;data/gis\u0026quot;)\rsaucier \u0026lt;- readOGR(\u0026quot;data/gis/Saucier_Geomorph_shapefile/Saucier_Geomorph.shp\u0026quot;) %\u0026gt;% st_as_sf() %\u0026gt;% sf::st_transform(\u0026quot;+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\u0026quot;)\r We can get a quick idea of what the data looks like with names() and a simple ggplot.\nnames(saucier)\r ## [1] \u0026quot;Formation\u0026quot; \u0026quot;Descrip\u0026quot; \u0026quot;Geo_Age\u0026quot; \u0026quot;geometry\u0026quot;\r ggplot() +\rgeom_sf(data = saucier,\raes(fill = Geo_Age),\rcolor = NA) +\rlabs(fill = \u0026quot;Geologic Age\u0026quot;) +\rscale_fill_brewer(type = \u0026quot;qual\u0026quot;, palette = \u0026quot;Accent\u0026quot;) +\rtheme_minimal()\r Included in the zipped download is an XML metadata file. I can parse it (with some trial and error) to get Formation and Geo_Age descriptions.\nmeta_xml \u0026lt;- read_xml(\u0026quot;data/gis/Saucier_Geomorph_shapefile/Saucier_Geomorph_FGDC.xml\u0026quot;)\r We can then take the XML document and manipulate it into a table with only the attributes we need.\nitem \u0026lt;- xml_find_all(meta_xml, \u0026quot;//edomv\u0026quot;) %\u0026gt;% xml_text() %\u0026gt;% factor()\ritem_desc \u0026lt;- xml_find_all(meta_xml, \u0026quot;//edomvd\u0026quot;) %\u0026gt;% xml_text() %\u0026gt;% as.character()\rmeta_table \u0026lt;- data.table::data.table(item, item_desc) %\u0026gt;% unique() %\u0026gt;% filter(nchar(item_desc) \u0026gt; 14)\rDT::datatable(meta_table,\rrownames = FALSE,\rcolnames = c(\u0026quot;Formation/Geo_Age\u0026quot;, \u0026quot;description\u0026quot;))\r \r{\"x\":{\"filter\":\"none\",\"data\":[[\"Had\",\"Hal\",\"Hb\",\"Hc\",\"Hchm\",\"Hcom\",\"Hcom-Projected\",\"Hcp\",\"Hdi\",\"Hdlp\",\"Hds\",\"Hnl\",\"Hp\",\"Hpu\",\"Pdch\",\"Pdp\",\"Pdu\",\"Pi\",\"Plm\",\"Ppch\",\"Ppp\",\"Ppu\",\"Ps\",\"Ptc\",\"Ptu\",\"Pvcl\",\"Pve\",\"Pvl\",\"RiverTrack\",\"Holocene\",\"Holocene (Alluvial Valley)\",\"Holocene (Deltaic and Chenier Plains)\",\"Pleistocene\"],[\"Principal abandoned deltaic distributaries. Distributaries grouped together and not separately delineated.\",\"Undifferentiated alluvium of small streams.\",\"Backswamp (floodbasin) deposits.\",\"Cheniers and relict beach ridges.\",\"Abandoned channels (neck and chute cutoffs) of the Mississippi River.\",\"Abandoned courses of the Mississippi River. Projected where removed by later subsequent small streams. Includes trunk channels of major delta complexes.\",\"Projected where removed by lateral migration of subsequent small streams. Includes trunk channels of major delta complexes.\",\"Undifferentiated paludal deposits of chenier plain. Represents brackish to saline marsh environments.\",\"Interdistributary deposits. Represents brackish to saline marsh environments.\",\"Lacustrine and lacustrine deltaic deposits of the Atchafalaya Basin.\",\"Inland swamp deposits. Represents freshwater swamp environment.\",\"Natural levees in deltaic plain associated with major distributaries and present Mississippi River. Natural levees that overlie interdistributary and other deltaic deposits, but not point bar deposits, are grouped together and not separately delineated.\",\"Point bar (meander scroll) deposits of Mississippi River, Arkansas River, Red River, and small streams. Meander belts of Arkansas, Mississippi, and Red Rivers are grouped together and not separately delineated.\",\"Point bar (meander scroll) and associated deposits of meander belts buried by backswamp deposits.\",\"Abandoned channels (cutoffs) of the Deweyville Complex.\",\"Point bar (meander scroll) deposits of the Deweyville Complex.\",\"Undifferentiated fluvial deposits of the Deweyville Complex.\",\"Undifferentiated fluvial deposits of the Intermediate Complex.\",\"Lacustrine deposits of the Deweyville (Lake Monroe) Complex. Levels are grouped together and not separately delineated.\",\"Abandoned channels (cutoffs) and short segments of Mississippi River abandoned courses of the Prarie Complex. Probable Wisconsin Stage.\",\"Point bar (meander scroll) deposits of Mississippi River origin of the Prarie Complex. Probable Wisconsin Stage. Levels are grouped together and not separately delineated.\",\"Undifferentiated fluvial deposits of the Prairie Complex. Mostly natural levee and backswamp deposits of Mississippi, Arkansas, Red Rivers. Levels are grouped together and not separately delineated.\",\"Sand dune fields and eolian deposits on valley trains.\",\"Undifferentiated fluvial deposits of the Cache River terrace.\",\"Undifferentiated fluvial deposits of probable Early Wisconsin Stage or earlier age.\",\"Relict channels of Late Wisconsin Stage valley train. Levels are grouped together and not separately delineated.\",\"Early Wisconsin Stage valley train. Interfluves and relict channels not separately delineated. Levels are grouped together and not separately delineated.\",\"Late Wisconsin Stage valley train. Includes both interfluve and relict channels unless channels delineated separately. Levels are grouped together and not separately delineated.\",\"Historic river tracks of the Mississippi River, Arkansas River, and oxbow lakes within the Lower Mississippi. Does not represent current river tracks nor current oxbow lakes.\",\"Position of river in 1994.\",\"Upland remnants of Tertiary age and terraces and ridges of Wisconsin and pre-Wisconsin age serve to subdivide the Mississippi alluvial valley into six major lowlands; each basin is a true topographic depression and definable hydrologic unit with a bounding interfluve; drainage is from north to south into a major collecting stream.\",\"Landforms within the deltaic and chenier plains that are as little as 5 to 10 ft above the surrounding landscape are often visible for miles, and a difference in elevation of inches may mean the difference between marsh and forest vegetation; features within the northern limit are piercement-type salt dome; abandoned distributaries are topographically prominent of the deltaic plain, but cheniers fill this role in the chenier plain.\",\"Quaternary features part of the Pleistocene epoch.\"]],\"container\":\"\\n \\n \\n Formation/Geo_Age\\n description\\n \\n \\n\",\"options\":{\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\rTo keep everything straight, I join this table with our sf object.\nsaucier_meta \u0026lt;- saucier %\u0026gt;% dplyr::left_join(meta_table, by = c(\u0026quot;Formation\u0026quot; = \u0026quot;item\u0026quot;)) %\u0026gt;% dplyr::left_join(meta_table, by = c(\u0026quot;Geo_Age\u0026quot; = \u0026quot;item\u0026quot;)) %\u0026gt;% dplyr::select(-item_desc.x) %\u0026gt;% st_as_sf()\r I also downloaded a recent shapefile of the Mississippi River in the state of Mississippi.\nms_r_1983 \u0026lt;- readOGR(\u0026quot;data/gis/ms_r/ms_r.shp\u0026quot;) %\u0026gt;%\rst_as_sf() %\u0026gt;%\rsf::st_transform(\u0026quot;+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\u0026quot;)\r I then saved my own {gggplot2} theme object and a few colors. Notice that I establish the font sizes all in one place, which makes it much easier to make small adjustments that will affect multiple aspects. I adjusted this theme frequently as I went along (I didn’t magically find all the right adjustments in one shot 😉).\nlibrary(showtext)\rshowtext_auto()\rfile \u0026lt;- sysfonts::font_files()\rfont_add(\u0026quot;Lato\u0026quot;, \u0026quot;Lato-Regular.ttf\u0026quot;)\rfont_add(\u0026quot;Open Sans Light\u0026quot;, \u0026quot;OpenSans-Light.ttf\u0026quot;)\rfont_add(\u0026quot;Open Sans Light Italic\u0026quot;, \u0026quot;OpenSans-LightItalic.ttf\u0026quot;)\rfont_add(\u0026quot;PT Sans\u0026quot;, \u0026quot;PTSans-Regular.ttf\u0026quot;)\rfont_add(\u0026quot;PT Serif\u0026quot;, \u0026quot;PTSerif-Regular.ttf\u0026quot;)\r## font sizes --------------------------------------------\rsize_header \u0026lt;- 14 * 3.4\rsize_axis_title \u0026lt;- 12* 3.4\rsize_legend_title \u0026lt;- 12* 3.4\rsize_axis_text \u0026lt;- 8* 3.4\rsize_legend_text \u0026lt;- 8* 3.4\rsize_caption \u0026lt;- 6* 3.4\r## color -------------------------------------------------\rbackground_color \u0026lt;- \u0026quot;white\u0026quot;\rmy_colors \u0026lt;- c(\r\u0026quot;#9BABBF\u0026quot;,\r\u0026quot;#8C694A\u0026quot;,\r\u0026quot;#6C733C\u0026quot;,\r\u0026quot;#D9B991\u0026quot;\r)\r## theme function -----------------------------------------\rmy_theme \u0026lt;- function(...) {\rtheme_void() +\rtheme(\r### plot and panel-----------------------------------\rplot.background = element_rect(\rfill = background_color,\rlinetype = 0,\rcolour = NA\r),\rpanel.background = element_rect(\rfill = background_color,\rlinetype = 0,\rcolor = NA\r),\rpanel.grid = element_blank(),\r# plot.margin = unit(c(.5, .5, .2, .5), \u0026quot;cm\u0026quot;),\rpanel.border = element_blank(),\r### title and caption -------------------------------\rtitle = element_text(family = \u0026quot;PT Serif\u0026quot;,\rsize = size_header),\rplot.caption = element_text(size = size_caption),\r### axis and strip text ------------------------------\rstrip.text = element_blank(),\raxis.title = element_text(size = size_axis_title),\raxis.text = element_text(size = size_axis_text),\r## legend text ----------------------------------------\rlegend.position = \u0026quot;right\u0026quot;,\rlegend.text = element_text(\rfamily = \u0026quot;Open Sans Light\u0026quot;,\rsize = size_legend_text\r)\r)\r}\r Explore geological ages and formations Holocene is our current geological epoch. The alluvial valley (or alluvial plain) is created by sediment deposits over the millenia. The soil deposits show where the Mississippi’s floodplain has been over time.\nsaucier_holocene \u0026lt;- saucier_meta %\u0026gt;% # all holocene features\rfilter(Geo_Age == \u0026quot;Holocene\u0026quot;)\rsaucier_holocene_alluvial \u0026lt;- saucier_meta %\u0026gt;% # holocene alluvial valley\rfilter(Geo_Age == \u0026quot;Holocene (Alluvial Valley)\u0026quot;,\rFormation %in% c(\u0026quot;Hchm\u0026quot;, \u0026quot;Hcom\u0026quot;, \u0026quot;Had\u0026quot;,\r\u0026quot;Ppch\u0026quot;, \u0026quot;Pdch\u0026quot;))\rggplot() +\rgeom_sf(data = saucier_holocene_alluvial,\raes(fill = Formation),\rcolor = NA) +\rgeom_sf(data = saucier_holocene,\rcolor = \u0026quot;#0066ff\u0026quot;) +\rlabs(title = \u0026quot;Mississippi River\u0026quot;,\rsubtitle = \u0026quot;Holocene and Alluvial Valley\u0026quot;,\rcaption = \u0026quot;USGS 2018\u0026quot;) +\rmy_theme() +\rtheme(axis.text = element_blank())\r Next, the Pleistocene (aka, the Ice Age). The pleistocene was around 2 million to 11 million years ago.\nsaucier_pleistocene \u0026lt;- saucier_meta %\u0026gt;% filter(Geo_Age == \u0026quot;Pleistocene\u0026quot;,\rFormation %in% c(\u0026quot;Hchm\u0026quot;, \u0026quot;Hcom\u0026quot;, \u0026quot;Had\u0026quot;,\r\u0026quot;Ppch\u0026quot;, \u0026quot;Pdch\u0026quot;))\r I picked out an area to focus on, so I can make a SpatialPolygons object to clip the other data to.\ne2 \u0026lt;- as(raster::extent(-91.2678, -90.7281,\r33.596, 34.25), \u0026quot;SpatialPolygons\u0026quot;) proj4string(e2) \u0026lt;- \u0026quot;+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\u0026quot;\r Clip data to close area.\nsaucier_holocene_alluvial_close \u0026lt;- st_intersection(saucier_holocene_alluvial %\u0026gt;% st_make_valid(),\rst_as_sf(e2))\rsaucier_holocene_close \u0026lt;- st_intersection(saucier_holocene,\rst_as_sf(e2))\rsaucier_pleistocene_close \u0026lt;- st_intersection(saucier_pleistocene,\rst_as_sf(e2))\rms_r_close \u0026lt;- st_intersection(ms_r_1983, st_as_sf(e2))\r We can take these close-ups and add a couple text labels with geom_text_repel() from ggrepel.\nggplot() +\rgeom_sf(data = saucier_holocene_alluvial_close,\rcolor = NA,\rfill = \u0026quot;#b97f74\u0026quot;) +\rgeom_text_repel(data = saucier_holocene_alluvial_close[2,],\raes(geometry = geometry),\rstat = \u0026quot;sf_coordinates\u0026quot;,\rnudge_x = -0.1,\rnudge_y = 0.2,\rlabel = str_wrap(\u0026quot;Abandoned channels and courses\u0026quot;,\rwidth = 15),\rfamily = \u0026quot;Open Sans Light Italic\u0026quot;,\rsize = 3\r) +\rscale_fill_brewer(type = \u0026quot;qual\u0026quot;) +\rgeom_sf(data = saucier_holocene_close,\rfill = \u0026quot;#e4d5b6\u0026quot;,\rcolor = NA) +\rgeom_text_repel(data = saucier_holocene_close[1,],\raes(geometry = geometry),\rstat = \u0026quot;sf_coordinates\u0026quot;,\rnudge_x = -0.1,\rnudge_y = 0.2,\rlabel = str_wrap(\u0026quot;Historical river track\u0026quot;,\rwidth = 15),\rfamily = \u0026quot;Open Sans Light Italic\u0026quot;,\rsize = 3 * 3.4\r) +\rgeom_sf(data = ms_r_close,\rinherit.aes = FALSE,\rfill = \u0026quot;#9fa066\u0026quot;,\rcolor = NA) +\rlabs(title = \u0026quot;Mississippi River\u0026quot;,\rsubtitle = \u0026quot;Holocene Alluvial Valley\u0026quot;,\rcaption = paste0(\u0026quot;USGS 2018, MARIS 1983\u0026quot;)) +\rmy_theme() +\rtheme(\raxis.text = element_blank(),\raxis.title = element_blank())\r Lets zoom in even closer, and add in a basemap to get some of those features in the original map with get_stamenmap() from ggmap.\nbase \u0026lt;- ggmap::get_stamenmap(bbox = c(-91.4, 33.6, -90.8, 34.0),\rmaptype = \u0026quot;terrain-lines\u0026quot;, messaging = FALSE, zoom = 12) %\u0026gt;% ggmap()\rlatit \u0026lt;- base$data$lat\rlong \u0026lt;- base$data$lon\rcoords \u0026lt;- matrix(c(latit, long),nrow = 4)\rp \u0026lt;- Polygon(coords = coords)\rps \u0026lt;- Polygons(list(p), 1)\rsps \u0026lt;- SpatialPolygons(list(ps)) %\u0026gt;% st_as_sf() %\u0026gt;% sf::st_set_crs(\u0026quot;+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\u0026quot;)\rpoly \u0026lt;- as(raster::extent(-91.4, -90.8, 33.6, 34.0), \u0026quot;SpatialPolygons\u0026quot;) %\u0026gt;%\rst_as_sf() %\u0026gt;%\rsf::st_set_crs(\u0026quot;+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\u0026quot;)\rbase +\rgeom_sf(data = saucier_holocene_alluvial_close,\rcolor = NA, inherit.aes = FALSE,\rfill = \u0026quot;#b97f74\u0026quot;) +\rgeom_sf(data = saucier_holocene_close,\rfill = \u0026quot;#e4d5b6\u0026quot;,\rinherit.aes = FALSE,\rcolor = NA,) +\rgeom_sf(data = saucier_pleistocene,\rinherit.aes = FALSE,\rfill = \u0026quot;green\u0026quot;) +\rgeom_sf(data = ms_r_1983,\rinherit.aes = FALSE,\rfill = \u0026quot;#9fa066\u0026quot;,\rcolor = NA) +\rlabs(title = \u0026quot;Mississippi River and Alluvial Valley\u0026quot;,\rfill = \u0026quot;Formation Description\u0026quot;,\rcaption = paste0(\u0026quot;USGS 2018, MARIS 1983\u0026quot;, \u0026quot;\\n\u0026quot;,\r\u0026quot;Basemap: Stamen\u0026quot;, \u0026quot;\\n\u0026quot;,\r\u0026quot;Liz Roten\u0026quot;)) +\rmy_theme() +\rtheme(axis.title = element_blank(),\rplot.caption = element_text(size = 6*3.4))\r Wisconsin glaciation The Wisconsin Glacial Episode was the most recent glacial period.\nsaucier_holocene_alluvial_closer \u0026lt;- st_intersection(st_make_valid(saucier_holocene_alluvial), st_as_sf(poly))\rsaucier_holocene_closer \u0026lt;- st_intersection(saucier_holocene,\rst_as_sf(poly))\rsaucier_pleistocene_closer \u0026lt;- st_intersection(st_make_valid(saucier),\rst_as_sf(poly)) %\u0026gt;% filter(Geo_Age == \u0026quot;Pleistocene\u0026quot;)\rsaucier_closer \u0026lt;- st_intersection(st_make_valid(saucier),\rst_as_sf(poly))\rms_r_closer \u0026lt;- st_intersection(ms_r_1983,\rst_as_sf(poly))\rprimary \u0026lt;- ggplot() +\rgeom_sf(data = saucier_pleistocene_closer,\rcolor = NA, inherit.aes = FALSE,\raes(fill = Formation)) +\rscale_fill_manual(values = c(\u0026quot;#8d977c\u0026quot;,\r\u0026quot;#716b2f\u0026quot;,\r\u0026quot;#bea85d\u0026quot;),\rlabels = c(\u0026quot;Prairie Complex\u0026quot;,\r\u0026quot;Early Wisconsin\u0026quot;,\r\u0026quot;Late Wisconsin\u0026quot;)) +\rgeom_sf(data = saucier_holocene_alluvial_closer,\rcolor = NA, inherit.aes = FALSE,\rfill = \u0026quot;#b97f74\u0026quot;) +\rgeom_sf(data = saucier_holocene_closer,\rfill = \u0026quot;#e4d5b6\u0026quot;,\rinherit.aes = FALSE,\rcolor = NA) +\rgeom_sf(data = ms_r_closer,\rinherit.aes = FALSE,\rfill = \u0026quot;#9fa066\u0026quot;,\rcolor = NA) +\rgeom_text_repel(data = saucier_holocene_closer[1,],\raes(geometry = geometry),\rstat = \u0026quot;sf_coordinates\u0026quot;,\rnudge_x = 0.2,\rnudge_y = -0.08,\rlabel = str_wrap(\u0026quot;Historical river track\u0026quot;,\rwidth = 15),\rfamily = \u0026quot;Open Sans Light Italic\u0026quot;,\rsize = 3*3.4\r) +\rgeom_text_repel(data = saucier_holocene_alluvial_closer[1,],\raes(geometry = geometry),\rstat = \u0026quot;sf_coordinates\u0026quot;,\rnudge_x = -0.1,\rnudge_y = 0,\rlabel = str_wrap(\u0026quot;Abandoned channels and courses\u0026quot;,\rwidth = 15),\rfamily = \u0026quot;Open Sans Light Italic\u0026quot;,\rsize = 3*3.4\r) +\rgeom_text_repel(data = ms_r_closer[5,],\raes(geometry = geometry),\rstat = \u0026quot;sf_coordinates\u0026quot;,\rnudge_x = -0.15,\rnudge_y = 0.05,\rlabel = str_wrap(\u0026quot;River track, 1983\u0026quot;, width = 15),\rfamily = \u0026quot;Open Sans Light Italic\u0026quot;,\rsize = 3*3.4\r) +\rlabs(title = \u0026quot;Mississippi River\u0026quot;,\rsubtitle = \u0026quot;Pleistocene features\u0026quot;,\rfill = \u0026quot;\u0026quot;,\rcaption = paste0(\u0026quot;USGS 2018, MARIS 1983\u0026quot;, \u0026quot;\\n\u0026quot;,\r\u0026quot;Liz Roten\u0026quot;)) +\rmy_theme() +\rtheme(axis.title = element_blank(),\raxis.text = element_blank(),\rplot.margin = unit(c(1,1,1,1), \u0026quot;mm\u0026quot;))\rprimary\r Context and inset map To add a little more context, lets use tidycensus to bring in the TIGER shapefiles of Mississippi, Louisiana, and Arkansas.\nall_states \u0026lt;- tigris::states(\rclass = \u0026quot;sf\u0026quot;,\ryear = 2018) %\u0026gt;% dplyr::select(NAME) %\u0026gt;% dplyr::filter(NAME %in% c(\u0026quot;Mississippi\u0026quot;,\r\u0026quot;Arkansas\u0026quot;,\r\u0026quot;Louisiana\u0026quot;)) %\u0026gt;% unique()\r Lets take a look at what we got from tidycensus.\nggplot() +\rgeom_sf(data = all_states,\rfill = \u0026quot;whitesmoke\u0026quot;,\rcolor = \u0026quot;darkgray\u0026quot;) +\rgeom_sf_text(data = all_states,\rlabel = all_states$NAME,\rnudge_y = -0.25,\rsize = 4,\rfamily = \u0026quot;Open Sans Light\u0026quot;) +\rgeom_sf(data = ms_r_1983,\rinherit.aes = FALSE,\rfill = \u0026quot;lightblue\u0026quot;,\rcolor = \u0026quot;lightblue\u0026quot;,\rsize = 1,\rcolor = NA) +\rggrepel::geom_text_repel(data = ms_r_1983[1,],\raes(geometry = geometry),\rstat = \u0026quot;sf_coordinates\u0026quot;,\rlabel = stringr::str_wrap(\u0026quot;Mississippi River\u0026quot;, width = 11), nudge_x = 1,\rnudge_y = -1,\rfamily = \u0026quot;Open Sans Light Italic\u0026quot;,\rsize = 3 * 3.4\r) +\rgeom_sf(data = poly,\rfill = NA, color = \u0026quot;black\u0026quot;,\rsize = 1) + labs(caption = paste0(\u0026quot;US ACS 2010, MARIS 1983\u0026quot;), title = \u0026quot;Mississippi River and surrounding states\u0026quot;) +\rmy_theme() +\rtheme_void()\r We can save a simplified version of the state map to serve as an inset map.\ninset \u0026lt;- ggplot() +\rgeom_sf(data = all_states,\rfill = \u0026quot;whitesmoke\u0026quot;,\rcolor = \u0026quot;darkgray\u0026quot;) +\rgeom_sf(data = ms_r_1983,\rinherit.aes = FALSE,\rfill = \u0026quot;lightblue\u0026quot;,\rcolor = \u0026quot;lightblue\u0026quot;,\rsize = 1,\rcolor = NA) +\rgeom_sf(data = poly,\rfill = NA, color = \u0026quot;black\u0026quot;,\rsize = 1) + my_theme() +\rtheme_void()\rinset \u0026lt;- as_grob(inset)\r ggdraw(primary) +\rdraw_grob(inset,\rscale = 0.3,\rhjust = -0.4,\rvjust = 0.3)\r Finally, lets save this map as an SVG.\nggsave(\u0026quot;final_map.svg\u0026quot;)\r Finishing up I don’t make static maps as often as I used to, so it was a bit weird doing map design work in RStudio, rather than ArcMap or Illustrator. There are a lot of tiny adjustments I want to make to the element positions. I exported the last map as an SVG, and then made some adjustments in Inkscape.\nI’m still not quite happy with the un-used white space on the right, but, hey, I’ll take it 🙇‍♂️.\nNotes Colors were inspired by the original map. I extracted the exact values using GIMP.\nPeople do so many cool things with Fisk’s map series! Check out a few below.\n Modern LIDAR images Quilts by Timna Tarr and Cathy Fussell  For the original plates check out these two sites.\n Georeferenced TIFs from USGS High resolution JPGs from Radical Cartography  You can read more about Harold Fisk’s work at Mapping Movement in American History and Culture.\nIf you are interested in more geology on the lower Mississippi alluvial valley, check out Fluvial geomorphic features of the Lower Mississippi alluvial valley by Lawson M. Smith.\nData citation Wacaster, S.R., Clark, J.M., Westerman, D.A., and Kress, W.H., 2018, Digital Dataset for the Geomorphology of the Lower Mississippi River Valley in Missouri, Kentucky, Arkansas, Tennessee, Louisiana, and Mississippi: U.S. Geological Survey data release, https://doi.org/10.5066/F7N878QN.\nThanks for reading! Feel free to leave a comment or question below.\n","date":1571270400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611592517,"objectID":"6096871ad43a702729238d5048abddaf","permalink":"lizroten.com/blog/fisk-s-mississippi-river-meander-in-r/","publishdate":"2019-10-17T00:00:00Z","relpermalink":"lizroten.com/blog/fisk-s-mississippi-river-meander-in-r/","section":"post","summary":"Background Those of us even mildly obsessed with maps will be familiar with Harold Fisk’s 1944 series documenting the historic travel of the Mississippi River in Mississippi River Alluvial Valley.","tags":["cartography","arcgis","ggplot2"],"title":"Fisk's 'Mississippi River Meander' in R","type":"post"},{"authors":["Liz Roten"],"categories":null,"content":"","date":1570492800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612038963,"objectID":"63f0c0f523b71f3f1c5f4628f8ec6052","permalink":"lizroten.com/talk/wilmds-streetlight-parks/","publishdate":"2019-10-08T00:00:00Z","relpermalink":"lizroten.com/talk/wilmds-streetlight-parks/","section":"talk","summary":"It’s one thing to know that transportation is a significant cause of greenhouse gas emissions — it’s another to quantify how much. To address the scarcity of transportation emissions data in Minnesota, the Metropolitan Council of the Twin Cities has developed greenhouse gas emission estimates for transportation and land for cities, townships, and counties of the Twin Cities Metropolitan Region. This session will demonstrate how to leverage big data to centralize this type of research, save public funding, and enable communities to focus their efforts on implementing strategies to become more sustainable.","tags":["Metropolitan Council","StreetLight Data","Parks"],"title":"Using location-based services to locate high activity areas within Twin Cities regional parks","type":"talk"},{"authors":null,"categories":null,"content":"Summary To better understand activity within Como Regional Park and how that activity shifts with the seasons, I created a hexagon grid over the park and then used aggregated and anonymized location-based services data provided by StreetLight Data to measure relative activity in each hexagon.\nThis project was my first endeavor with Tableau and was used as a pilot before we dedicated additional resources to using StreetLight Data for parks research.\nDetails StreetLight Data Data in this data visualization comes from StreetLight, an independent data provider which cleans, processes and assimilates millions of spatial data points from a combination of mobile phone Location-Based Services (LBS) data and GPS data. The data is anonymized, aggregated, and accessed only through specific analyses.\nThis viz draws on LBS data. Cell phone apps that use LBS collect the device\u0026rsquo;s location in space and time. StreetLight detects trips, a movement with clear start and stop locations. StreetLight uses trips to create the StreetLight Traffic Index, which is a normalized measure of the relative traffic, or activity, in an area. The data’s spatial precision is 65ft or better and StreetLight estimates a 23% penetration rate for the combined US and Canada adult population.\nAnalysis For this viz, we made a hexagon grid over Como Regional Park. We then ran a StreetLight analysis to measure the relative traffic in each hexagon and repeated the analysis for Winter (November 2017 - February 2018), Summer (May 2018 - August 2018), and all 2018. StreetLight returns a Traffic Index value for each hexagon for every trip intersection type, day type, and day part configuration.\nInteractive Map In the Tableau viz, you can view the analysis results. Each hexagon on the map changes color according to its Traffic Index, or activity level. The darker the color, the higher the traffic. You can view the exact Traffic Index value of any hexagon by hovering over it. Use the map tools in the upper left corner to pan, zoom, and adjust the map view. We suggest you view this story in full screen for the best display.\n","date":1561075200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612038992,"objectID":"d2f23d1027d50272b923e9186fb28341","permalink":"lizroten.com/project/como-hex-streetlight-parks/","publishdate":"2019-06-21T00:00:00Z","relpermalink":"lizroten.com/project/como-hex-streetlight-parks/","section":"project","summary":"Visualize high activity areas within Como Regional Park and seasonal trends","tags":["Metropolitan Council","StreetLight Data","Parks","Tableau"],"title":"Como Regional Park Hex Grid StreetLight Analysis","type":"project"},{"authors":["Liz Roten"],"categories":null,"content":"","date":1559952000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612038963,"objectID":"1ced15f14dc52b9b09b05d1880fe908d","permalink":"lizroten.com/talk/tcrg-streetlight-parks/","publishdate":"2019-06-08T00:00:00Z","relpermalink":"lizroten.com/talk/tcrg-streetlight-parks/","section":"talk","summary":"StreetLight Data provides aggregated cell phone location data for transportation research. This talk will examine how the Research Team at the Metropolitan Council is using StreetLight to analyze visitor patterns in regional parks. We will cover topics including inferring traveler demographics -- such as race, income, education, and family status -- and limitations of the data. Finally, we will explore interactive visualizations using this powerful data source.","tags":["Metropolitan Council","StreetLight Data","Parks"],"title":"Using Location-based Data in Regional Parks Visitors Research","type":"talk"},{"authors":["Liz Roten"],"categories":null,"content":"\rClick the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.\r\r\rSupplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605995682,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"lizroten.com/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"lizroten.com/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot;\rif porridge == \u0026quot;blueberry\u0026quot;:\rprint(\u0026quot;Eating...\u0026quot;)\r  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\r Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\r Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}}\r{{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}\r  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604006534,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"lizroten.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"lizroten.com/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":[],"categories":["cartography"],"content":"A map I made during my time at Macalester College.\n","date":1510185600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611524977,"objectID":"812dbeca1080b9e9ac86e5fb372bd057","permalink":"lizroten.com/blog/hiv-and-african-american-populations-in-the-us/","publishdate":"2017-11-09T00:00:00Z","relpermalink":"lizroten.com/blog/hiv-and-african-american-populations-in-the-us/","section":"post","summary":"A map I made during my time at Macalester College.","tags":["design","map","arcgis","bivariate choropleth","HIV","health disparities","epidemiology","cartography"],"title":"HIV and African American Populations in the US","type":"post"},{"authors":[],"categories":["cartography"],"content":"About the Process I use eMoods to track my mental health from day to day. For this viz, I used eMoods data, as well as my Google Location History data, to display my life between February 2015 and October 2017. I used ggplot2 in R Studio to generate the radial bar charts on the far rights, and Adobe Illustrator to construct the bar graphs in the bottom left corner. For the heatmaps, I first attempted to use ArcGIS to view data I downloaded from my Google account directly but quickly found that software to be limiting for the goals of this project I forked and modified Location History Visualizer using JavaScript, HTML, and CSS to use my own color scheme and preferred base map. I assembled the images in Adobe Illustrator and presented this work for my class.\nI worked with geospatial data in formats I was unfamiliar with, such as KML, JSON, and tar.gz zipped files. I also had no prior experience in Adobe Illustrator, JavaScript, HTML, and CSS. This piece not only demonstrates my skill in these areas but also my persistence and commitment to telling my story.\nDuring my Spring 2018 independent project, I also used R Shiny to take a simple, interactive look at the polar coordinate bar graphs. You can see this app on its own here and the updated version here.\n\n","date":1509321600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611524977,"objectID":"e19291c7bbf3dc6339568b0b9b6a371e","permalink":"lizroten.com/blog/3-years-of-mental-health-a-quantified-self-story/","publishdate":"2017-10-30T00:00:00Z","relpermalink":"lizroten.com/blog/3-years-of-mental-health-a-quantified-self-story/","section":"post","summary":"About the Process I use eMoods to track my mental health from day to day. For this viz, I used eMoods data, as well as my Google Location History data, to display my life between February 2015 and October 2017.","tags":["arcgis","ggplot2","design","illustrator","personal","Shiny"],"title":"3 Years of Mental Health: A quantified-self story","type":"post"},{"authors":["Liz Roten","Robert Ford"],"categories":null,"content":"\rClick the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.\r\r\r\rClick the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.\r\r\rSupplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605995682,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"lizroten.com/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"lizroten.com/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Liz Roten","Robert Ford"],"categories":null,"content":"\rClick the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.\r\r\r\rClick the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.\r\r\rSupplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605995682,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"lizroten.com/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"lizroten.com/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"}]