[{"authors":null,"categories":null,"content":"I am a highly motivated data scientist and cartographer with a passion for data visualization. I make complex topics easy to understand using compelling visual design. My static and interactive visualizations are attractive and powerful tools for decision making.\nBehind the plots and maps, I’ve successfully built organization-specific R packages for processing gigabytes of information quickly, managing consistent visual identity across products, and standardizing data cleaning practices.\n  View and download my CV.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1650138358,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://lizroten.com/author/liz-roten/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/liz-roten/","section":"authors","summary":"I am a highly motivated data scientist and cartographer with a passion for data visualization. I make complex topics easy to understand using compelling visual design. My static and interactive visualizations are attractive and powerful tools for decision making.","tags":null,"title":"Liz Roten","type":"authors"},{"authors":["吳恩達"],"categories":null,"content":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bb560906b6a99893cc21387348c0b074","permalink":"https://lizroten.com/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"吳恩達","type":"authors"},{"authors":[],"categories":["plots with code"],"content":"Color palette I’m having a moment with linen, so I decided to make my color palette for my rstudio conference talk match some of my favorite hues.\nColors based on {dutchmasters}, semi.joan’s instagram, and Blackbird Fabrics collection of linen.\ndutch_white \u0026lt;- dutchmasters$pearl_earring[\u0026#34;white(colar)\u0026#34;] brick \u0026lt;- colorRampPalette(c(\u0026#34;#A65746\u0026#34;, dutch_white)) midnight \u0026lt;- colorRampPalette(c(\u0026#34;#5A6E73\u0026#34;, dutch_white)) clay \u0026lt;- colorRampPalette(c(\u0026#34;#59302D\u0026#34;, dutch_white)) taupe \u0026lt;- colorRampPalette(c(\u0026#34;#BFB3A4\u0026#34;, dutch_white)) acorn \u0026lt;- colorRampPalette(c(\u0026#34;#BF895A\u0026#34;, dutch_white)) seaweed \u0026lt;- colorRampPalette(c(\u0026#34;#262001\u0026#34;, dutch_white)) noil_black \u0026lt;- colorRampPalette(c(\u0026#34;#0D0D0D\u0026#34;, dutch_white)) white \u0026lt;- colorRampPalette(c(dutch_white, \u0026#34;#FFFFFF\u0026#34;))  Function to create palette ramp with a set number of levels.\ncreate_palette_ramp \u0026lt;- function(x = 50) { tibble::tibble( family = c( rep(\u0026#34;brick\u0026#34;, x), rep(\u0026#34;midnight\u0026#34;, x), rep(\u0026#34;clay\u0026#34;, x), rep(\u0026#34;taupe\u0026#34;, x), rep(\u0026#34;acorn\u0026#34;, x), rep(\u0026#34;noil_black\u0026#34;, x), rep(\u0026#34;white\u0026#34;, x), rep(\u0026#34;seaweed\u0026#34;, x) ), level = c(rep(1:x, 8)), code = c( brick(x), midnight(x), clay(x), taupe(x), acorn(x), noil_black(x), white(x), seaweed(x) ) ) %\u0026gt;% dplyr::arrange(-level) } palette_ramp50 \u0026lt;- create_palette_ramp()  ggplot( palette_ramp50, aes( x = level, y = family, color = code ) ) + geom_point( size = 25.4, shape = 15 ) + scale_color_identity() + scale_y_discrete(limits = rev) + labs( title = \u0026#34;Color palette\u0026#34;, caption = my_caption ) + theme_minimal() + theme( axis.title = element_blank(), axis.text.x = element_blank(), axis.text.y = element_text(size = 40, hjust = 0), plot.title = element_text(size = 50), panel.grid = element_blank(), plot.caption = element_text(family = \u0026#34;Nunito\u0026#34;, size = 25) )  Gradient bubbles Notice {purrr} use to generate a plot for each color all at once.\nset.seed(24601) split_palette \u0026lt;- create_palette_ramp(200) %\u0026gt;% filter(family != \u0026#34;white\u0026#34;) %\u0026gt;% arrange(family, -level) %\u0026gt;% group_by(family) %\u0026gt;% group_split() purrr::map(split_palette, function(x) { p \u0026lt;- ggplot( x, aes( x = family, y = level, color = code ) ) + geom_jitter( size = 38, width = .55, height = 0, alpha = 0.90 ) + scale_color_identity() + # scale_y_discrete(limits = rev) + coord_cartesian( clip = \u0026#34;off\u0026#34;, xlim = c(0.952, 1.058), ylim = c(-11.5, 208) ) + labs(caption = my_caption) + theme_minimal() + theme( axis.title = element_blank(), axis.text.x = element_blank(), panel.grid = element_blank(), axis.text.y = element_blank(), plot.caption = element_text( family = \u0026#34;Nunito\u0026#34;, size = 25, color = noil_black(1), vjust = -1, margin = margin(10, 0, 0, 0, \u0026#34;pt\u0026#34;) ), plot.caption.position = \u0026#34;plot\u0026#34;, plot.margin = margin(5, 5, 10, 5, \u0026#34;pt\u0026#34;), plot.background = element_rect( fill = dutch_white, colour = NA ) ) }) ## [[1]]  ## ## [[2]]  ## ## [[3]]  ## ## [[4]]  ## ## [[5]]  ## ## [[6]]  ## ## [[7]]  Gradient bubbles with bars set.seed(24602) split_palette_bubble \u0026lt;- create_palette_ramp(200) %\u0026gt;% filter(family != \u0026#34;white\u0026#34;) %\u0026gt;% arrange(family, -level) %\u0026gt;% group_by(family) %\u0026gt;% group_split() purrr::map(split_palette_bubble, function(x) { max_level \u0026lt;- max(x$level) ggplot( x, aes( x = family, y = level, color = code ) ) + geom_jitter( size = 25, width = 0.5, height = 0.2, alpha = 0.5 ) + scale_color_identity() + geom_hline( yintercept = max_level * 0.55, color = x$code[max_level * 0.45], size = 8 ) + geom_hline( yintercept = max_level * 0.5, color = x$code[max_level * 0.5], size = 10 ) + geom_hline( yintercept = max_level * 0.45, color = x$code[max_level * 0.55], size = 8 ) + coord_cartesian( clip = \u0026#34;off\u0026#34;, # xlim = c(-0.2, 0.2), ylim = c(-5, 205) ) + labs(caption = my_caption) + theme_minimal() + theme( axis.title = element_blank(), axis.text.x = element_blank(), panel.grid = element_blank(), axis.text.y = element_blank(), plot.background = element_rect( fill = x$code[max_level * 0.5], colour = NA ), plot.caption = element_text( family = \u0026#34;Nunito\u0026#34;, size = 25, color = ifelse(unique(x$family) %in% c( \u0026#34;acorn\u0026#34;, \u0026#34;taupe\u0026#34; ), \u0026#34;black\u0026#34;, \u0026#34;white\u0026#34;), vjust = -1, margin = margin(10, 0, 0, 0, \u0026#34;pt\u0026#34;) ), plot.caption.position = \u0026#34;plot\u0026#34;, plot.margin = margin(5, 5, 10, 5, \u0026#34;pt\u0026#34;) ) }) ## [[1]]  ## ## [[2]]  ## ## [[3]]  ## ## [[4]]  ## ## [[5]]  ## ## [[6]]  ## ## [[7]]  Diverging bubbles set.seed(24601) select_pal \u0026lt;- create_palette_ramp(400) %\u0026gt;% filter(family %in% c( \u0026#34;brick\u0026#34;, \u0026#34;clay\u0026#34;, \u0026#34;acorn\u0026#34; # \u0026#34;taupe\u0026#34; )) %\u0026gt;% arrange(family, level) p \u0026lt;- ggplot( select_pal, aes( y = family, x = level, color = code ) ) + geom_jitter( size = 38, height = .45, width = 0, alpha = 0.90 ) + scale_color_identity() + scale_y_discrete(limits = rev) + coord_cartesian(clip = \u0026#34;off\u0026#34;) + theme_minimal() + theme( axis.title = element_blank(), axis.text.x = element_blank(), panel.grid = element_blank(), axis.text.y = element_blank(), plot.background = element_rect( fill = dutch_white, colour = NA ) ) p + (p + scale_x_reverse()) + labs(caption = my_caption) + theme( plot.caption = element_text( family = \u0026#34;Nunito\u0026#34;, size = 25, color = \u0026#34;black\u0026#34;, vjust = -1, margin = margin(15, 0, 0, 0, \u0026#34;pt\u0026#34;) ), plot.caption.position = \u0026#34;plot\u0026#34;, plot.margin = …","date":1656979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657126567,"objectID":"61b66c9b5c29115f9bc771803ea98517","permalink":"https://lizroten.com/post/color-palette-exploration/","publishdate":"2022-07-05T00:00:00Z","relpermalink":"/post/color-palette-exploration/","section":"post","summary":"Color palette exploration with ggplot2 and generative methods","tags":["rtistry","ggplot2","purrr","aRtsy","patchwork","tibble","tidyverse","dutchmasters","visualization"],"title":"Color palette exploration","type":"post"},{"authors":null,"categories":null,"content":"The study update process began in 2021 with a few goals.\n Migrate existing calculations and documentation scattered in Excel workbooks, ArcGIS documents, and PDFs to reproducible R code and RMarkdown documents, complete with version control and testing. Re-score existing corridors using most recent available data. Evaluate new truck corridors and freight facilities as submitted by agency partners.  Throughout the process, I carefully balanced preserving the original methodology and accounting for each data source’s quirks.\nSome data used in the original study were unavailable. Working with our transportation planners, I developed a method for estimating truck volume and truck percentage of total traffic using StreetLight Data. I then carefully integrated the data sources and patched missing data to complete the project. Finally, I completed an comprehensive project wrap-up, tracking down emails, chat messages, and meeting notes to compile a definitive “how” and “why” for each data source and analysis method. I used {groundhog} to preserve package versions and implemented a clever script naming convention to organize files. Documentation is a love letter to your future self - and I went all out.\nInteractive I decided to build the visualization using Tableau because I wanted to take advantage of Tableau’s dynamic tooltips, in which you can insert a mini plot. The interaction between elements, such as a map and a table, is more streamlined. Tableau can also turn out a snazzy visualization relatively quickly.\nScreenshots     Background Regional truck freight corridors were initially developed through the 2017 Regional Truck Highway Corridors Study. A technical advisory work group of public agency staff most directly engaged in highway planning guided this data-driven study that analyzed the region’s principal and minor arterials. Ultimately the study applied four data factors to establish corridor score rankings and to group the corridors into tiers 1, 2, and 3, in order of priority.\nIn 2018 the Met Council adopted the study’s final regional truck corridors into the Transportation Policy Plan and first applied the tiered corridors as project selection criteria in the Regional Solicitation process for distributing federal transportation funds. The corridors have also been used as qualifying criteria in recent funding cycles of MnDOT’s Minnesota Highway Freight Program.\n","date":1640908800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"7a1dd6db2a724e3c35708bb86ad3ea26","permalink":"https://lizroten.com/project/truck-corridor-study/","publishdate":"2021-12-31T00:00:00Z","relpermalink":"/project/truck-corridor-study/","section":"project","summary":"Making a legacy project reproducible","tags":["code optimization","From Excel to R","reproducible research","Metropolitan Council","interactive","visualization","tableau","GIS","cartography","spatial conflation","spatial operations","public data","transportation","StreetLight Data"],"title":"Regional Truck Corridor Study","type":"project"},{"authors":[],"categories":["tutorial"],"content":"I’ve been obsessed with Ijeamaka Anyene’s art for months now. Her zine is gorgeous, and I’ve been antsy to try some of the techniques out.\nSpokes: Pattern 01 Variants # setup library(tidyverse) library(colorspace) set.seed(246153) library(showtext) showtext_auto() file \u0026lt;- sysfonts::font_files() font_add(\u0026#34;Nunito Light\u0026#34;, \u0026#34;Nunito-Light.ttf\u0026#34;) font_add(\u0026#34;Cormorant Garamond\u0026#34;, \u0026#34;CormorantGaramond-Regular.ttf\u0026#34;) my_caption \u0026lt;- \u0026#34;Liz Roten | @LizRoten\u0026#34;  See original here.\nlines \u0026lt;- tibble( x = seq(0, 29, by = 0.2), xend = rep(0,146), y = runif(146, min = 5, max = 9), yend = rep(0,146), speed = 3 ) ggplot() + geom_segment(data = lines, aes(x = x, y = y, xend = xend, yend = yend), color = \u0026#34;white\u0026#34;, alpha = 0.5) + geom_point(data = lines, aes(x = x, y = y), color = \u0026#34;white\u0026#34;) + coord_polar() + scale_x_continuous(limits = c(0, 29)) + # scale_y_continuous(limits = c(-1, 10)) + labs(caption = my_caption) + theme_void() + theme(plot.background = element_rect(fill = \u0026#34;#14342B\u0026#34;, color = NA), panel.background = element_rect(fill = \u0026#34;#14342B\u0026#34;, color = NA), plot.caption = element_text(family = \u0026#34;Nunito Light\u0026#34;, color = \u0026#34;white\u0026#34;, size = 12), plot.margin = unit(c(.5, .5, .2, .5), \u0026#34;cm\u0026#34;) )  Spokes: Pattern 10 Variants See original here.\nincrement = .05 circle_1 = tibble( x = seq(from = 0, to = 5, by = increment), xend = seq(from = 0, to = 5, by = increment), y = 0, yend = 1.4, type = LETTERS[1]) circle_2 = tibble( x = seq(from = 0, to = 5, by = increment + increment), xend = seq(from = 0, to = 5, by = increment + increment), y = 1.5, yend = 2.9, type = LETTERS[2]) circle_3 = tibble( x = seq(from = 0, to = 5, by = increment ), xend = seq(from = 0, to = 5, by = increment ), y = 3, yend = 4.5, type = LETTERS[3]) palette_values = c(\u0026#34;#94524A\u0026#34;, \u0026#34;#8d667e\u0026#34;, \u0026#34;#39355c\u0026#34;) bind_rows(circle_1, circle_2, circle_3) %\u0026gt;% ggplot(.) + geom_segment(aes(x = x, y = y, xend = xend, yend = yend, color = type), show.legend = F) + scale_color_manual(values = palette_values) + labs(caption = my_caption) + coord_polar() + theme_void() + theme( # plot.background = element_rect(fill = \u0026#34;#565254\u0026#34;, # color = NA, # size = 0), # panel.background = element_rect(fill = \u0026#34;#565254\u0026#34;, # color = NA, # size = 0), plot.caption = element_text(family = \u0026#34;Nunito Light\u0026#34;, color = \u0026#34;black\u0026#34;, hjust = 1, size = 14), plot.caption.position = \u0026#34;plot\u0026#34;, plot.margin = unit(c(.5, .5, .5, .5), \u0026#34;cm\u0026#34;) )  increment = .05 circle_1 = tibble( x = seq(from = 0, to = 5, by = increment), xend = seq(from = 0, to = 5, by = increment), y = 0, yend = 1.5, type = LETTERS[1]) circle_2 = tibble( x = seq(from = 0, to = 5, by = increment), xend = seq(from = 0, to = 5, by = increment), y = 1.5, yend = 3, type = LETTERS[2]) circle_3 = tibble( x = seq(from = 0, to = 5, by = increment ), xend = seq(from = 0, to = 5, by = increment ), y = 3, yend = 4.5, type = LETTERS[3]) palette_values = c(\u0026#34;#7A443E\u0026#34;, colorspace::lighten(\u0026#34;#7A443E\u0026#34;, 0.5), colorspace::lighten(\u0026#34;#7A443E\u0026#34;, 0.8)) bind_rows(circle_1, circle_2, circle_3) %\u0026gt;% ggplot(.) + geom_segment(aes(x = x, y = y, xend = xend, yend = yend, color = type), show.legend = F) + scale_color_manual(values = palette_values) + labs(caption = my_caption) + coord_polar() + theme_void() + theme( plot.caption = element_text(family = \u0026#34;Nunito Light\u0026#34;, color = \u0026#34;black\u0026#34;, hjust = 1, size = 14), plot.caption.position = \u0026#34;plot\u0026#34;, plot.margin = unit(c(.5, .5, .5, .5), \u0026#34;cm\u0026#34;) )  Florals I fell in love with the opening slide in Ijeamaka Anyene’s talk at RLadies Johannesburg, so I wanted to give it a try!\nset.seed(246153) burst \u0026lt;- tibble( x = seq(0, 10, by = 0.3), xend = seq(0,10, by = 0.3), y = 0, yend = 0.4, yend_jitt = jitter(yend, 2.6), yend_jitt_point = yend_jitt ) plot_burst \u0026lt;- ggplot() + geom_segment(data = burst, aes(x = x, y = y, xend = xend, yend = yend_jitt), color = \u0026#34;#F4AC32\u0026#34;, lwd = 0.5) + geom_point(data = burst, aes(x = x, y = yend_jitt), color = \u0026#34;#F4AC32\u0026#34;, size = 1.5 ) + coord_polar() + theme_void() bursts \u0026lt;- quote(expr = {cowplot::draw_plot(plot_burst, scale = runif(1, min = 1.2, max = 3), x = runif(1, min = 0, max = 10), y = runif(1, min = 0, max = 5))}) plot_all \u0026lt;- cowplot::ggdraw(xlim = c(0,12), ylim = c(0,6)) + eval(bursts) + eval(bursts) + eval(bursts) + eval(bursts) + eval(bursts) + eval(bursts) + eval(bursts) + eval(bursts) + eval(bursts) + labs(caption = my_caption) + theme(plot.background = element_rect(fill = \u0026#34;#565254\u0026#34;, color = NA, size = 0), panel.background = element_rect(fill = \u0026#34;#565254\u0026#34;, color = NA, size = 0), plot.caption = element_text(family = \u0026#34;Nunito Light\u0026#34;, color = \u0026#34;white\u0026#34;, hjust = 1, size = 14), plot.caption.position = \u0026#34;plot\u0026#34;, plot.margin = unit(c(.5, .5, .5, .5), \u0026#34;cm\u0026#34;) ) plot_all  See also  Ijeamaka Anyene’s fantastic zine Colors via https://coolors.co/  ","date":1617321600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"2ac5fc1d22d567f665fc42862a0e75fa","permalink":"https://lizroten.com/post/rtistry-with-contour/","publishdate":"2021-04-02T00:00:00Z","relpermalink":"/post/rtistry-with-contour/","section":"post","summary":"Generative art using ggplot2","tags":["rtistry","ggplot2","visualization"],"title":"Radial rtistry","type":"post"},{"authors":[],"categories":["cartography"],"content":"I made a pretty neat header image for this site using raster data from my Square Lake Master Plan Update project.\nlibrary(sf) library(ggplot2) library(dplyr) library(Cairo)  Download regional park geography from Minnesota Geospatial Commons.\n## base geometries ------------------------------------------------------------- temp \u0026lt;- tempfile() download.file(\u0026#34;ftp://ftp.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/plan_parks_regional/gpkg_plan_parks_regional.zip\u0026#34;, destfile = temp ) square_lake \u0026lt;- sf::read_sf(unzip(temp, \u0026#34;plan_parks_regional.gpkg\u0026#34;)) %\u0026gt;% filter(STATUS == \u0026#34;Existing\u0026#34;) %\u0026gt;% filter(PARKNAME == \u0026#34;Square Lake\u0026#34;) %\u0026gt;% group_by(PARKNAME, AGENCY) %\u0026gt;% sf::st_union() %\u0026gt;% st_as_sf() %\u0026gt;% st_transform(4326) fs::file_delete(\u0026#34;plan_parks_regional.gpkg\u0026#34;)  I refined contours.RDS in my previous project. The data come from MnTOPO, a web application for viewing, printing and downloading high-resolution elevation data for the State of Minnesota that was collected using LiDAR technology. I only needed data from a small area, so I drew a polygon over my study area using MnTOPO.\n# load 3 meter contours over the Square Lake area contour \u0026lt;- readRDS(\u0026#34;contours.RDS\u0026#34;) %\u0026gt;% st_transform(4326) %\u0026gt;% sf::st_crop(xmin = -92.7854633, ymin = 45.1497518, xmax = -92.8007197, ymax = 45.1568488)  Generate plot with {ggplot2}.\nggplot() + geom_sf( data = contour, color = \u0026#34;gray75\u0026#34;, lwd = 0.2 ) + theme_void()  Finally, save the plot as a PDF and open it in Adobe Illustrator for modifications.\nCairo::CairoPDF(file = \u0026#34;contours.pdf\u0026#34;, onefile = TRUE, width = 12, height = 10, bg = \u0026#34;transparent\u0026#34;) ggplot() + geom_sf( data = contour, color = \u0026#34;gray75\u0026#34;, lwd = 0.2 ) + theme_void() dev.off()  I adjusted the background and finessed the positioning so it would display like I wanted it to on my home page. Here is the final product.\n   ","date":1615593600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"d7ef2a2132efb25b899667cf7ada5968","permalink":"https://lizroten.com/post/make-a-neat-header/","publishdate":"2021-03-13T00:00:00Z","relpermalink":"/post/make-a-neat-header/","section":"post","summary":"Create an eye-catching website header","tags":["cartography","parks","illustrator","ggplot2"],"title":"Make a neat header image","type":"post"},{"authors":null,"categories":null,"content":"","date":1614038400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"efb74352773068a972fc4781a163b94f","permalink":"https://lizroten.com/project/emoods-blog-post/","publishdate":"2021-02-23T00:00:00Z","relpermalink":"/project/emoods-blog-post/","section":"project","summary":"A guest blog post I authored at emoodtracker.com","tags":["visualization","blog","writing"],"title":"How eMoods Aided My Recovery And Inspired My Data Science Career","type":"project"},{"authors":null,"categories":null,"content":"Background In May 2019, I completed an R Shiny app visualizing regional parks and trails in context with American Community Survey (ACS) demographic data. The project’s first iteration was built as a mini-app to be used in workshop sessions with regional parks implementing agencies. Later, I re-structured the backend to follow the {golem} framework\n Regional Parks and the American Community Survey is a mini-app designed for use by Regional Parks implementing agencies to assist in their progressing toward a more equitable use of regional parks. The app complements the Regional Parks Equity Toolkit, a set of questions and a process to clarify how regional park projects are advancing equity. The app facilitates direct examination of regional parks and trails system and the demographic characteristics of the census tracts surrounding them.\n New developments After I transitioned to my split between Community Development (CD) and Metropolitan Transportation Services (MTS) divisions, another team member took the project on. I supported that person in building skills in {shiny} and {golem}. I also used GitHub to manage app enhancements and document workflow.\nNow, the app boasts a sophisticated modeling component, estimating the demographic characteristics of populations within a given distance, or buffer, around the park or trail. We expect the update to roll out around Q2 2021.\n   ","date":1612483200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"bc80649127b662dca98843985b01bfb2","permalink":"https://lizroten.com/project/regional-parks-acs/","publishdate":"2021-02-05T00:00:00Z","relpermalink":"/project/regional-parks-acs/","section":"project","summary":"Progressing toward a more equitable use of regional parks","tags":["Metropolitan Council","parks","shiny","golem","interactive","visualization"],"title":"Regional Parks and the American Community Survey","type":"project"},{"authors":null,"categories":null,"content":"{councilR} is the Metropolitan Council’s custom R package. Features include corporate color codes, {ggplot2} themes, functions for accessing local and remote GIS data, and a set of RStudio snippets. The package is open-source and used by myself and my colleagues daily.\n{councilR} is managed via GitHub Actions, ensuring functionality on multiple operating systems and neatly evaluating new features.\n","date":1612483200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"8328df6b16d939745821999d9c265524","permalink":"https://lizroten.com/project/councilr-package/","publishdate":"2021-02-05T00:00:00Z","relpermalink":"/project/councilr-package/","section":"project","summary":"An organization-specific R package for curated templates, palettes, functions, and more!","tags":["Metropolitan Council","packages","github","pkgdown","GitHub Actions"],"title":"{councilR}","type":"project"},{"authors":null,"categories":null,"content":"An R package for pulling data for Minnesota Department of Transportation (MnDOT) loop detectors installed on the Minnesota Freeway system in 30-second interval measurements of occupancy and volume, data which are pushed daily to a public JSON feed.\n{tc.sensors} is managed via GitHub Actions, ensuring functionality on multiple operating systems and neatly evaluating new features.\n","date":1612483200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"35affff1fd70d87f2b88fda6f65a07b6","permalink":"https://lizroten.com/project/tc-sensors/","publishdate":"2021-02-05T00:00:00Z","relpermalink":"/project/tc-sensors/","section":"project","summary":"Functions to pull sensor data, sensor IDs, and sensor configuration for MnDOT metro district","tags":["Metropolitan Council","packages","github","pkgdown","transportation","GitHub Actions"],"title":"{tc.sensors}","type":"project"},{"authors":null,"categories":null,"content":"Summary Square Lake Park Special Recreation Feature recently underwent a master plan update. I served on the technical advisory committee (TAC) and conducted a focused analysis estimating annual visitation and visitor activity within the park. I presented findings to Washington County staff and the entire TAC.\nOverall visitation Square Lake Park has just one entrance and is surrounded by relatively low-traffic roads. I drew a gate over the park entrance and estimated the number of vehicles that pass through the gate using StreetLight Volume. Then, I applied a persons-per-vehicle multiplier to estimate the number of visitors. I also used StreetLight’s visitor home location metrics to estimate the spatial distribution of visitors.\n  Liz Roten for Metropolitan Council, 2021  Activity within the park To visualize visitor activity within the park, I generated a hexagon grid and ran StreetLight analyses for different trip intersection types.\nThese maps visualize the activity within Square Lake Park on an average day during operating hours (6am - 10pm) in Summer 2019. Each map shows a grid of hexagons covering Square Lake Park. The hexagons are colored such that darker shades indicate greater activity, and lighter shades indicate lower activity. Each trip intersection type highlights the ways in which visitors enjoy the park. However, activity on Square Lake, such as paddling, boating, or using the fishing pier, is not detected.\n View a higher resolution of this viz here   StreetLight Data Data in this data visualization comes from StreetLight Data, an independent data provider which cleans, processes and assimilates millions of spatial data points from a combination of mobile phone Location-Based Services (LBS) data and GPS data. The data is anonymized, aggregated, and accessed only through specific analyses.\n","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"2caf3ef41e7d66d7ca173cd52854f20c","permalink":"https://lizroten.com/project/square-lake-master-plan/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/project/square-lake-master-plan/","section":"project","summary":"Utilizing aggregated LBS data to asses activity patterns within Square Lake Park and estimated visitor home location","tags":["Metropolitan Council","StreetLight Data","parks","visualization","static","design","illustrator"],"title":"Square Lake Park Master Plan","type":"project"},{"authors":[],"categories":["tutorial"],"content":"Around the holidays, my partner and I decided to bring a stationary exercise bike into our home. After many pros and cons lists, we opted for the Bowflex C6. I decided to try out this whole Peloton thing, and quickly found that the resistance adjustments are not equivalent between the Peloton bike and the C6. Thankfully, there is a wonderful subreddit just for this model! The folks there directed me to this conversion chart, which then led me to a 3D-printed plate to keep on my handlebars.\nAs I kept going along in my classes, all I could think was “What does this look like on a plot? What is the distribution?” Here is the result.\nLoad packages ## load packages library(dplyr) library(tidyr) library(purrr) library(ggplot2) library(Cairo) ## theme and Peloton(c) red source(\u0026#34;theme.R\u0026#34;) pelo_red \u0026lt;- \u0026#34;#df1c2f\u0026#34;  You can find theme.R in this site’s GitHub repo.\nCreate tibble Create data table.\nconv_table \u0026lt;- tibble(C6 = c(0, 5, 9, 17, 25, 33, 49, 100), Peloton = c(0, 25, 30, 35, 40, 45, 50, 100), Difficulty = seq(from = 0, to = 10, length.out = 8 )) conv_table_long \u0026lt;- conv_table %\u0026gt;% gather(C6, Peloton, key = \u0026#34;Bike\u0026#34;, value = \u0026#34;Resistance\u0026#34;)  Plot Make the plot.\nplot \u0026lt;- ggplot(data = conv_table_long) + geom_smooth(mapping = aes(x = Difficulty, y = Resistance, color = Bike), se = FALSE) + scale_color_manual(values = c(\u0026#34;white\u0026#34;, pelo_red), labels = c(\u0026#34;Bowflex C6\u0026#34;, \u0026#34;Peloton\u0026#34;)) + scale_x_continuous(n.breaks = 3, labels = c(\u0026#34;Easy\u0026#34;, \u0026#34;Hard\u0026#34;, \u0026#34;Impossible\u0026#34;)) + labs(title = \u0026#34;Spin bike resistance\u0026#34;, subtitle = \u0026#34;Peloton vs. Bowflex C6\u0026#34;, x = \u0026#34;Difficulty\u0026#34;, caption = \u0026#34;@LizRoten 2021 | Data r/pelotoncycle\u0026#34;) + my_theme  Display plot\nplot     Update! I was scrolling through aforementioned r/SchwinnIC4_BowflexC6 and found a post by another data person!\n2021-07-08 It seems as though the Reddit user (u/raintower579) who created the formula has drifted into spam territory. The comment they made with the formula has been deleted. See the actual post here. Huge thanks to Phillip for contacting me regarding this.\n$$ y = 0.0171x^2 - 0.64x + 9.1429 $$\nwhere x is the Peloton resistance and y is the C6 resistance.\npelo_conversion \u0026lt;- function(x){ (0.0171*x^2) - (0.64*x) + 9.1429 }  To estimate the equivalence beyond 50, we can create a new tibble and apply the function to a sequence of Peloton resistance settings. Instructors don’t tend to call out any value below 20, so we can start there.\ntibble(peloton_resistance = seq(20,100,5)) %\u0026gt;% # create Peloton resistance sequence, 20-100 by 5s mutate(c6_resistance = round(pelo_conversion(peloton_resistance), 1)) #\u0026gt; # A tibble: 17 x 2 #\u0026gt; peloton_resistance c6_resistance #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 20 3.2 #\u0026gt; 2 25 3.8 #\u0026gt; 3 30 5.3 #\u0026gt; 4 35 7.7 #\u0026gt; 5 40 10.9 #\u0026gt; 6 45 15 #\u0026gt; 7 50 19.9 #\u0026gt; 8 55 25.7 #\u0026gt; 9 60 32.3 #\u0026gt; 10 65 39.8 #\u0026gt; 11 70 48.1 #\u0026gt; 12 75 57.3 #\u0026gt; 13 80 67.4 #\u0026gt; 14 85 78.3 #\u0026gt; 15 90 90.1 #\u0026gt; 16 95 103. #\u0026gt; 17 100 116.  By this table, I’ve been making my classes much harder than necessary.\nWe can plot this function, as shown below.\nggplot(data = conv_table, aes(x = Peloton, y = C6)) + geom_function( fun = pelo_conversion, color = \u0026#34;white\u0026#34;) + stat_function( fun = pelo_conversion, geom = \u0026#34;point\u0026#34;, color = pelo_red, size = 2, n = 17) + scale_x_continuous(limits = c(20, 100)) + scale_y_continuous(limits = c(0, 100)) + labs(title = \u0026#34;Peloton to Bowflex C6 resistance conversion\u0026#34;, x = \u0026#34;Peloton\u0026#34;, y = \u0026#34;Bowflex C6\u0026#34;, caption = \u0026#34;@LizRoten 2021 | Data r/pelotoncycle\u0026#34;) + my_theme2  The big, flashing caveat here is that every bike is calibrated just slightly differently, so this might not be correct for the machine in my bedroom.\n","date":1611619200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"032bc7076db6aca417bda29c46727189","permalink":"https://lizroten.com/post/bowflex-c6-to-peloton-resistance-conversion-plots/","publishdate":"2021-01-26T00:00:00Z","relpermalink":"/post/bowflex-c6-to-peloton-resistance-conversion-plots/","section":"post","summary":"Not all magnetic resistance systems are created the same","tags":["ggplot2","peloton","personal"],"title":"Converting Peloton resistance to Bowflex C6 resistance","type":"post"},{"authors":[],"categories":["tutorial","cartography"],"content":"Goal Use {edgebundle} to map flight patterns over the US.\n# remotes::install_github(\u0026#34;schochastics/edgebundle\u0026#34;) library(edgebundle) library(igraph) library(ggplot2) library(ggraph) library(dplyr) library(sf) library(tigris) set.seed(24601) my_caption \u0026lt;- c(\u0026#34;Liz Roten (@LizRoten) | Data: openflights.org\u0026#34;)  We also need to use the Python library, datashader. {edgebundle} ships with a nice function for installing all the dependencies.\nedgebundle:::install_bundle_py()  Data prep The data we will use is us_flights, which is shipped with {edgebundle}. us_flights is a complex object.\nflights \u0026lt;- us_flights # name us_flights coords \u0026lt;- cbind(V(flights)$longitude, V(flights)$latitude) # extract coordinates # create vertex sequence verts \u0026lt;- data.frame(x = V(flights)$longitude, y = V(flights)$latitude)  Supporting data To make our output a little more aesthetically pleasing, we will go ahead and transform the data to use Albers Equal Area Conic.\nstates \u0026lt;- tigris::states(cb = TRUE, progress_bar = FALSE) %\u0026gt;% filter(STUSPS %in% state.abb, !NAME %in% c(\u0026#34;Alaska\u0026#34;, \u0026#34;Hawaii\u0026#34;)) %\u0026gt;% sf::st_transform(crs = \u0026#34; +proj=aea +lat_1=20 +lat_2=60 +lat_0=40 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m no_defs\u0026#34;)  coords_full \u0026lt;- cbind(V(flights)$longitude, V(flights)$latitude, V(flights)$name) # extract coordinates coords_sf \u0026lt;- st_as_sf(x = as.data.frame(coords_full), coords = c(\u0026#34;V1\u0026#34;, \u0026#34;V2\u0026#34;), crs = 4326) %\u0026gt;% sf::st_transform(crs = \u0026#34; +proj=aea +lat_1=20 +lat_2=60 +lat_0=40 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m no_defs\u0026#34;)  Edge bundle Create edge bundles\nforce_bundle \u0026lt;- edge_bundle_force(flights, xy = coords, compatibility_threshold = 0.6) force_bundle_sf \u0026lt;- force_bundle %\u0026gt;% st_as_sf(coords = c(\u0026#34;x\u0026#34;, \u0026#34;y\u0026#34;), crs = 4326) %\u0026gt;% sf::st_transform(crs = \u0026#34; +proj=aea +lat_1=20 +lat_2=60 +lat_0=40 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m no_defs\u0026#34;) %\u0026gt;% rowwise() %\u0026gt;% mutate(x_coord = st_coordinates(geometry)[[1]], y_coord = st_coordinates(geometry)[[2]])  Create map source(\u0026#34;theme.R\u0026#34;)  base_plot \u0026lt;- geom_sf(data = states, color = \u0026#34;white\u0026#34;, fill = NA, lwd = 0.1)  final_map \u0026lt;- ggplot() + base_plot + geom_path(data = force_bundle_sf, aes(x = x_coord, y = y_coord, group = group), color = line_color, size = 0.5, alpha = 0.2) + geom_path(data = force_bundle_sf, aes(x = x_coord, y = y_coord, group = group), color = \u0026#34;white\u0026#34;, size = 0.005, alpha = 0.1) + geom_sf(data = coords_sf, color = line_color, size = 0.25) + geom_sf(data = coords_sf, color = \u0026#34;white\u0026#34;, size = 0.25, alpha = 0.1) + labs(title = \u0026#34;US Flight Network\u0026#34;, # subtitle = \u0026#34;Force Bundle Method\u0026#34;, caption = my_caption) + my_theme final_map  To get the sizing just right on the final image I posted on Twitter, I adjusted the size of my viewing panel in RStudio until I was happy with the dimensions.\nCredits This entire post was inspired by Dominic Royé.\nTrying a very nice new tool, thanks to {edgebundle} package created by @schochastics. Here the European flight network in a bundle flow version. #rstats #rspatial #datavis pic.twitter.com/dty4tTSYdE\n— Dr. Dominic Royé (@dr_xeo) December 19, 2020  You can find my tweet with this map here.\n","date":1608336000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"2e95c7c3010527be395a389204cdcc73","permalink":"https://lizroten.com/post/maps-with-edgebundle/","publishdate":"2020-12-19T00:00:00Z","relpermalink":"/post/maps-with-edgebundle/","section":"post","summary":"Replicating a snappy map","tags":["ggplot2","tidyverse","cartography"],"title":"Maps with {edgebundle}","type":"post"},{"authors":["Liz Roten","Ashley Asmus","Jonathan Ehrlich"],"categories":null,"content":"","date":1603843200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657646074,"objectID":"aba64a9dfbf06db6376b7be8e3065928","permalink":"https://lizroten.com/talk/ampo-covid-traffic/","publishdate":"2020-10-28T00:00:00Z","relpermalink":"/talk/ampo-covid-traffic/","section":"talk","summary":"To estimate public adherence to social distancing guidelines during the Coronavirus outbreak, we analyzed departures from “typical” traffic volumes on the metro freeway system of the Twin Cities region.","tags":["Metropolitan Council","COVID","Conference"],"title":"Monitoring public adherence to social distancing guidelines with traffic data","type":"talk"},{"authors":["Liz Roten","Mauricio Leon","Catherine Manzo"],"categories":null,"content":"Conferences We’ve had the pleasure of presenting this project at multiple conferences. See the list below.\n AMPO 2020 (October 2020) Minnesota’s Transportation Conference (March 2021)  ","date":1603843200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657646074,"objectID":"832142d2ac0a1322d721f7a6c7cbe084","permalink":"https://lizroten.com/talk/ampo-streetlight-ghg/","publishdate":"2020-10-28T00:00:00Z","relpermalink":"/talk/ampo-streetlight-ghg/","section":"talk","summary":"To address the scarcity of transportation emissions data in Minnesota, the Metropolitan Council of the Twin Cities has developed greenhouse gas emission estimates for transportation and land for cities, townships, and counties of the Twin Cities Metropolitan Region.","tags":["Metropolitan Council","StreetLight Data","Climate","Conference"],"title":"Using location-based services data for calculating the transportation greenhouse gas emissions of communities in Minnesota's Metropolitan Region","type":"talk"},{"authors":null,"categories":null,"content":"Twin Cities Rent Trends is a dashboard for analyzing rental housing market trends in the seven-county Twin Cities region. Rent data can be difficult and costly to obtain, and different sources can yield significantly different values. This app allows users to compare each source and view the data at different geographic levels. Users can view rent trends, including absolute rent price, rents adjusted for inflation, and year-over-year percent change. Users can also visualize the relationship between rent and vacancy rates (not available for all data sources).\nI built the app based on the {golem} framework, which builds the app repository as an R package. The result is a robust Shiny app, complete with testing and modular elements. The app integrates other package I’ve developed, including {council.skeleton} and {councilR}.\nScreenshots      ","date":1603411200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"3e4b956d59dce16e4e458c06e545a98b","permalink":"https://lizroten.com/project/twin-cities-rent-trends/","publishdate":"2020-10-23T00:00:00Z","relpermalink":"/project/twin-cities-rent-trends/","section":"project","summary":"Visualize rent and vacancy trends for cities, townships, and neighborhoods in the Twin Cities","tags":["Metropolitan Council","housing","shiny","golem","rent","interactive","visualization"],"title":"Twin Cities Rent Trends","type":"project"},{"authors":null,"categories":null,"content":"I developed a methodology for estimating greenhouse gas emissions from passenger and commercial vehicles for every city or township in the Twin Cities region. Data implemented include aggregated, anonymized location-based services data provided by StreetLight Data, the Environmental Protection Agency’s MOVES model, and MnDOT’s vehicle classification data. The resulting data is implemented in the Council’s larger greenhouse gas inventory, which quantifies emissions from sources including energy, transportation, agriculture, and waste management.\nThe data is also available in our interactive tool, Twin Cities Greenhouse Gas Inventory\nYou can find more information on the Council’s website here.\n Climate change is occurring all around the world, including right here in the Twin Cities region. Minnesota has already experienced more extreme rainfall and warmer winters due to climate change, and more changes are on the way. The good news is that local jurisdictions can take meaningful action now to address climate change.\n  The climate is changing due to human activities which release greenhouse gases (GHGs) into the atmosphere and cause average temperatures to rise. Many human activities emit carbon dioxide, as well as even more powerful greenhouse gases like methane, nitrous oxide, and others. Each of these gases exist naturally in the environment, but human-built systems for energy, transportation, agriculture, and waste management are responsible for releasing climate-altering quantities of these gases.\n ","date":1594857600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"9c68b12ce78996d73c1d770300dc0d2e","permalink":"https://lizroten.com/project/greenhouse-gas-inventory/","publishdate":"2020-07-16T00:00:00Z","relpermalink":"/project/greenhouse-gas-inventory/","section":"project","summary":"Estimating commercial and personal vehicle emissions with location-based services data","tags":["Metropolitan Council","StreetLight Data"],"title":"Greenhouse Gas Emissions Inventory","type":"project"},{"authors":null,"categories":null,"content":" The maps in this series were last updated July 15, 2020. Since then, the state has opened additional testing locations and implemented new testing options, including no cost home testing. For the most recent information regarding COVID-19 testing in Minnesota, please see the Minnesota Department of Health website.   The COVID-19 response effort requires all hands on deck, and my team at the Metropolitan Council has been working with folks at the State of Minnesota to help answer transportation-related questions. In summer 2020, we got a request for analyzing how COVID-19 testing centers are distributed across the state so as to inform where more resources may be needed. I created a series of maps visualizing the nearest distance (by travel duration/network distance and linear distance) between random points across the state and COVID-19 testing facilities. I created maps for the entire state, as well as specific regions across the state.\nMethod I designated all federally qualified health centers in Minnesota as testing centers. Many of these health centers were already in the testing center dataset but might have slight variations in the site name or address. To keep things simple, I appended the federally qualified health centers to the testing center dataset.\nBoth distance and estimated duration were calculated using the same method. I generated a 0.5 square mile hexagon grid over the entire state and then chose a random point within each hex. I calculated the network distance and estimated travel duration from the point to the three nearest (by linear distance) testing centers. Rather than calculating distance from all 300+ testing centers, I narrowed it down to just the three nearest to reduce computing time. Of those three nearest centers, I found the shortest possible distance in miles and shortest possible travel duration in minutes and applied that to the entire hexagon.\nDistance and estimated duration were calculated using Open Source Routing Machine (OSRM), a well-established open source project which utilizes OpenStreetMap (OSM) road network data. OSM is crowd-sourced but has proven very reliable and accurate in academic studies and is used for a variety of applications across public and private sectors, including several projects at the Council. OSRM is cited as “Copyright © Project OSRM contributors”.\nNote that this is an estimated general travel duration that does not consider congestion at different times of day, days of the week, weather conditions, roadway conditions, and other factors that affect travel time.\nMinnesota region-specific maps                ","date":1594771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"001a34bbf2ac73cf0faa68046160b4ef","permalink":"https://lizroten.com/project/mdh-covid-maps/","publishdate":"2020-07-15T00:00:00Z","relpermalink":"/project/mdh-covid-maps/","section":"project","summary":"A map series analyzing how COVID-19 testing centers are distributed across Minnesota","tags":["Metropolitan Council","health","cartography","covid","transportation","static","visualization"],"title":"Minimum distance to COVID-19 testing facilities","type":"project"},{"authors":null,"categories":null,"content":"Prior to 2019, regional parks use estimates were completed using a series of Excel workbooks, originally written in the 1990s. A colleague re-wrote the procedure in a single RMarkdown document for the 2018 estimates. Later, I developed {use.estimates}, which spread the calculation process over multiple vignettes. Each vignette produces a report for each step in the process, which allowed our parks researcher to review results quickly. All package data is also documented for future data scientists.\nThis package is managed via GitHub such that new Issues and pull requests are integrated into project management. The package is regularly tested using GitHub Actions.\nYou can see the published use estimate reports here\n","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"fe4c0112d10bc18d9f446fab9f789aeb","permalink":"https://lizroten.com/project/regional-parks-use-estimates/","publishdate":"2020-06-01T00:00:00Z","relpermalink":"/project/regional-parks-use-estimates/","section":"project","summary":"A set of reusable tools for calculating and visualizing annual regional parks use estimates","tags":["Metropolitan Council","packages","github","pkgdown","parks","documentation","modernizing","GitHub Actions"],"title":"{use.estimates}","type":"project"},{"authors":null,"categories":null,"content":"In early 2020, the transportation and modeling team at the Metropolitan Council began using traffic data from the Minnesota Department of Transportation (MnDOT) to evaluate the impact of recent physical distancing efforts on regional and statewide travel. I developed an accompanying R Shiny app with sections for visualizing the model results, downloading tabular data, and explaining the model. Individual items include an interactive plot showing the percent difference from expected traffic levels and an interactive map displaying the change in expected traffic at individual traffic sensors across the Twin Cities metro area and Rochester area.\nI built the app based on the {golem} framework, which builds the app repository as an R package. The result is a robust Shiny app, complete with testing and modularized elements. The app integrates other package I’ve developed, including {council.skeleton} and {councilR}. The first iteration of the app was published within a week of starting on it.\nScreenshots The plot shows the daily relative decrease in freeway travel over time across the Twin Cities metropolitan region after March 1. Points that fall below the zero-line represent decreases in travel relative to typical travel on that day of the year and day of the week. Typical travel is estimated using a statistical analysis of traffic volumes from 2018, 2019, and 2020 prior to March 1.\n   The map shows the decreases in travel at individual traffic monitoring sites across the Twin Cities Metropolitan area. Traffic monitoring is performed by the Minnesota Department of Transportation (MnDOT) using detectors built into the infrastructure of the roads. These detectors are usually used to estimate congestion along Metro area highways.\n   Relevent links Official news release\nLive app site (updated regularly)\nGitHub repository\n","date":1590105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"fffbb588bb3759de8e951f67af8b75a8","permalink":"https://lizroten.com/project/covid-traffic-trends/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"/project/covid-traffic-trends/","section":"project","summary":"Monitoring social distance guideline adherence with traffic data","tags":["Metropolitan Council","shiny","golem","interactive","visualization"],"title":"COVID Traffic Trends","type":"project"},{"authors":[],"categories":["tutorial"],"content":"I am a knitter. Knitting is a calming, fulfilling practice that keep my hands busy and require just enough brain power to keep my mind from wandering too far. Over the past winter, I conquered my fear of making socks, and now I profess that I am a sock knitter. I made socks for Christmas gifts, and churned out four pairs during my evenings, bus commutes, long work meetings, lectures, coffee and tea shop visits (basically everywhere). I’m comfortable with the standard stockinette sock, and I even ventured out into other patterns from Ravelry (the social medium for yarn folks), like Hermione’s Everyday Socks and the Slip It Simple Socks.\nBut, even as the weather is warming here in Minnesota, working from home means that I don’t have a commute and COVID-19 means that I have plenty of spare angst, so I’ve decided to make a new pair of socks, and work with a new pattern.\nAnd, just when I was starting to glaze over scrolling through endless Ravelry pages and reviews, I found ravelRy, an R package that interfaces seamlessly with Ravelry’s API. And its even on CRAN!\nLets install, and get going!\ninstall.packages(\u0026#34;ravelRy\u0026#34;)  library(ravelRy) library(tidyverse)  Authentication As with most APIs, you need to authenticate somehow. I’ll use my Ravelry account credentials (you’ll need a free, pro account to access the API).\nravelRy::ravelry_auth(key = \u0026#34;username\u0026#34;) ravelRy::ravelry_auth(key = \u0026#34;password\u0026#34;)  Search for a sock pattern! Lets start simple, and just look for the first 20 results for “sock” that are available as a Ravelry download.\nsearch_result \u0026lt;- search_patterns( query = \u0026#34;sock\u0026#34;, page_size = 20, craft = \u0026#34;knitting\u0026#34;, # knitting or crochet fit = \u0026#34;adult\u0026#34;, # adult, baby, etc. ravelry_download = TRUE ) head(search_result) #\u0026gt; # A tibble: 6 x 7 #\u0026gt; free id name permalink designer.id designer.name pattern_sources #\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; #\u0026gt; 1 FALSE 1222621 Engelkrista~ engelkri~ 34635 Caia Gossens \u0026lt;df [2 x 60]\u0026gt; #\u0026gt; 2 TRUE 1250944 Vecna vecna 97793 Dots Dabbles \u0026lt;df [1 x 60]\u0026gt; #\u0026gt; 3 FALSE 1229788 Plaid Pocke~ plaid-po~ 111830 Shuyi Wu \u0026lt;df [2 x 60]\u0026gt; #\u0026gt; 4 TRUE 1235715 Cably Wably cably-wa~ 32564 Liz Sedmak \u0026lt;df [2 x 60]\u0026gt; #\u0026gt; 5 FALSE 1091238 DRK Everyda~ drk-ever~ 78156 Andrea Mowry \u0026lt;df [1 x 60]\u0026gt; #\u0026gt; 6 TRUE 1244939 Sock Prince~ sock-pri~ 92088 Annette Schl~ \u0026lt;df [1 x 60]\u0026gt;  The fourth result is even my old friend, “Hermione’s Everyday Socks!”\nsearch_result[4, ] # get the fourth row in the table #\u0026gt; # A tibble: 1 x 7 #\u0026gt; free id name permalink designer.id designer.name pattern_sources #\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; #\u0026gt; 1 TRUE 1235715 Cably Wably cably-wab~ 32564 Liz Sedmak \u0026lt;df [2 x 60]\u0026gt;  Lets take a look at the actual pattern from the search results using get_patterns().\nhermione \u0026lt;- get_patterns(ids = search_result[4, ]$id) str(hermione, max.level = 2) #\u0026gt; tibble [1 x 50] (S3: tbl_df/tbl/data.frame) #\u0026gt; $ comments_count : int 4 #\u0026gt; $ created_at : chr \u0026#34;2022/04/19 09:02:36 -0400\u0026#34; #\u0026gt; $ currency : chr \u0026#34;USD\u0026#34; #\u0026gt; $ difficulty_average : num 6.36 #\u0026gt; $ difficulty_count : int 150 #\u0026gt; $ downloadable : logi FALSE #\u0026gt; $ favorites_count : int 428 #\u0026gt; $ free : logi TRUE #\u0026gt; $ gauge : num 8 #\u0026gt; $ gauge_divisor : int 1 #\u0026gt; $ gauge_pattern : chr \u0026#34;stockinette stitch\u0026#34; #\u0026gt; $ generally_available : chr \u0026#34;2022/04/01 00:00:00 -0400\u0026#34; #\u0026gt; $ id : int 1235715 #\u0026gt; $ name : chr \u0026#34;Cably Wably\u0026#34; #\u0026gt; $ pdf_url : chr \u0026#34;\u0026#34; #\u0026gt; $ permalink : chr \u0026#34;cably-wably\u0026#34; #\u0026gt; $ price : chr \u0026#34;\u0026#34; #\u0026gt; $ projects_count : int 848 #\u0026gt; $ published : chr \u0026#34;2022/04/01\u0026#34; #\u0026gt; $ queued_projects_count : int 55 #\u0026gt; $ rating_average : num 4.55 #\u0026gt; $ rating_count : int 152 #\u0026gt; $ row_gauge : num 11 #\u0026gt; $ updated_at : chr \u0026#34;2022/06/09 18:40:59 -0400\u0026#34; #\u0026gt; $ url : chr \u0026#34;\u0026#34; #\u0026gt; $ yardage : int 350 #\u0026gt; $ yardage_max : int 500 #\u0026gt; $ personal_attributes : chr \u0026#34;\u0026#34; #\u0026gt; $ sizes_available : chr \u0026#34;Small (8.5”, 21.5 cm) (Large (9.5”, 24 cm)) actual circumference\u0026#34; #\u0026gt; $ product_id : chr \u0026#34;\u0026#34; #\u0026gt; $ currency_symbol : chr \u0026#34;$\u0026#34; #\u0026gt; $ ravelry_download : logi FALSE #\u0026gt; $ download_location : chr \u0026#34;\u0026#34; #\u0026gt; $ pdf_in_library : logi FALSE #\u0026gt; $ volumes_in_library : chr \u0026#34;\u0026#34; #\u0026gt; $ gauge_description : chr \u0026#34;8 stitches and 11 rows = 1 inch in stockinette stitch\u0026#34; #\u0026gt; $ yarn_weight_description: chr \u0026#34;Fingering (14 wpi)\u0026#34; #\u0026gt; $ yardage_description : chr \u0026#34;350 - 500 yards\u0026#34; #\u0026gt; $ pattern_needle_sizes :List of 1 #\u0026gt; $ notes_html : chr \u0026#34;\\n\u0026lt;p\u0026gt;These socks were designed for Round 3 of the 2022 Sock Madness competition and will be exclusive to the pl\u0026#34;| __truncated__ #\u0026gt; $ notes : chr \u0026#34;These socks were designed for Round 3 of the 2022 Sock Madness competition and will be exclusive to the players\u0026#34;| __truncated__ #\u0026gt; $ packs :List of 1 #\u0026gt; $ printings :List of 1 #\u0026gt; $ yarn_weight :List of 1 #\u0026gt; $ craft :List of 1 #\u0026gt; $ pattern_categories :List of 1 #\u0026gt; $ pattern_attributes :List of 1 #\u0026gt; $ pattern_author :List of 1 #\u0026gt; $ photos :List of 1 #\u0026gt; $ pattern_type :List of 1 str(hermione$pattern_attributes) #\u0026gt; List of 1 #\u0026gt; $ : tibble [16 x 2] (S3: tbl_df/tbl/data.frame) #\u0026gt; ..$ id : int [1:16] 3 10 12 18 22 25 56 64 204 207 ... #\u0026gt; ..$ permalink: chr [1:16] \u0026#34;unisex\u0026#34; \u0026#34;adult\u0026#34; \u0026#34;negative-ease\u0026#34; …","date":1586304000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"03075de9e4a69b23fbb38c4fe5de07f3","permalink":"https://lizroten.com/post/finding-the-perfect-sock-pattern-with-ravelry/","publishdate":"2020-04-08T00:00:00Z","relpermalink":"/post/finding-the-perfect-sock-pattern-with-ravelry/","section":"post","summary":"Using Ravelry's API to find just the right sock pattern","tags":["tidyverse","ggplot2","ravelry"],"title":"Finding the perfect sock pattern with {ravelRy}","type":"post"},{"authors":[],"categories":["tutorial"],"content":"     Background Those of us even mildly obsessed with maps will be familiar with Harold Fisk’s 1944 series documenting the historic travel of the Mississippi River in Mississippi River Alluvial Valley. In my house in college, filled with geography majors and map enthusiasts, we had a small print hung on the wall, and it was easy to start reading it, and end up standing there, just staring, for quite a while.\nEven viewing on a screen, its easy to see how you can get lost in the map. The colors are distinct and vivid, and the contextual information, like political boundaries and fault lines, against the aged sepia base do not distract. The map is dynamic, with irregular shapes and curves. If not done right, the messiness could overwhelm the viewer, but Fisk succeeds in capturing the audience’s attention. The content itself makes you reconsider your relationship with this body of water. Seeing how it has moved and changed course over time reminds you of how small, short and insignificant our lives can be compared to the Earth’s natural history.\n   I adore this map. I won’t attempt to fully recreate it here, but I want to explore the data behind it, and see what I can find.\nPrep Lets load in packages I know I’ll need.\nlibrary(rgdal) library(dplyr) library(sf) library(ggplot2) library(leaflet) library(xml2) library(data.table) library(raster) library(ggrepel) library(stringr) library(ggmap) library(tidycensus) library(cowplot)  To start, I studied the map and did an inventory of the elements.\n State lines Elevation Mississippi River Rivers other than the Mississippi County lines Cut offs (neck, chute, and fault) Lakes Major landmarks Flood areas Much more!  I was having difficulty working with raster elevation data, so I decided to save that for another day. However, there is a dataset from a 1994 study by Roger T. Saucier, “Geomorphology and Quaternary Geologic History of the Lower Mississippi Valley, Volumes I and II.” The United States Geological Survey (USGS) developed both georeferenced plates and vector shapefiles. I downloaded both the datasets from the USGS website.\nData cleaning I downloaded the zipped shapefile, so here I unzip the folder, read in the shapefile, and convert it to an sf object.\nunzip(\u0026#34;data/gis/Saucier_Geomorph_shapefile.zip\u0026#34;, exdir = \u0026#34;data/gis\u0026#34;) saucier \u0026lt;- readOGR(\u0026#34;data/gis/Saucier_Geomorph_shapefile/Saucier_Geomorph.shp\u0026#34;) %\u0026gt;% st_as_sf() %\u0026gt;% sf::st_transform(\u0026#34;+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\u0026#34;)  We can get a quick idea of what the data looks like with names() and a simple ggplot.\nnames(saucier)  ## [1] \u0026#34;Formation\u0026#34; \u0026#34;Descrip\u0026#34; \u0026#34;Geo_Age\u0026#34; \u0026#34;geometry\u0026#34;  ggplot() + geom_sf(data = saucier, aes(fill = Geo_Age), color = NA) + labs(fill = \u0026#34;Geologic Age\u0026#34;) + scale_fill_brewer(type = \u0026#34;qual\u0026#34;, palette = \u0026#34;Accent\u0026#34;) + theme_minimal()  Included in the zipped download is an XML metadata file. I can parse it (with some trial and error) to get Formation and Geo_Age descriptions.\nmeta_xml \u0026lt;- read_xml(\u0026#34;data/gis/Saucier_Geomorph_shapefile/Saucier_Geomorph_FGDC.xml\u0026#34;)  We can then take the XML document and manipulate it into a table with only the attributes we need.\nitem \u0026lt;- xml_find_all(meta_xml, \u0026#34;//edomv\u0026#34;) %\u0026gt;% xml_text() %\u0026gt;% factor() item_desc \u0026lt;- xml_find_all(meta_xml, \u0026#34;//edomvd\u0026#34;) %\u0026gt;% xml_text() %\u0026gt;% as.character() meta_table \u0026lt;- data.table::data.table(item, item_desc) %\u0026gt;% unique() %\u0026gt;% filter(nchar(item_desc) \u0026gt; 14) DT::datatable(meta_table, rownames = FALSE, colnames = c(\u0026#34;Formation/Geo_Age\u0026#34;, \u0026#34;description\u0026#34;))   {\u0026#34;x\u0026#34;:{\u0026#34;filter\u0026#34;:\u0026#34;none\u0026#34;,\u0026#34;vertical\u0026#34;:false,\u0026#34;data\u0026#34;:[[\u0026#34;Had\u0026#34;,\u0026#34;Hal\u0026#34;,\u0026#34;Hb\u0026#34;,\u0026#34;Hc\u0026#34;,\u0026#34;Hchm\u0026#34;,\u0026#34;Hcom\u0026#34;,\u0026#34;Hcom-Projected\u0026#34;,\u0026#34;Hcp\u0026#34;,\u0026#34;Hdi\u0026#34;,\u0026#34;Hdlp\u0026#34;,\u0026#34;Hds\u0026#34;,\u0026#34;Hnl\u0026#34;,\u0026#34;Hp\u0026#34;,\u0026#34;Hpu\u0026#34;,\u0026#34;Pdch\u0026#34;,\u0026#34;Pdp\u0026#34;,\u0026#34;Pdu\u0026#34;,\u0026#34;Pi\u0026#34;,\u0026#34;Plm\u0026#34;,\u0026#34;Ppch\u0026#34;,\u0026#34;Ppp\u0026#34;,\u0026#34;Ppu\u0026#34;,\u0026#34;Ps\u0026#34;,\u0026#34;Ptc\u0026#34;,\u0026#34;Ptu\u0026#34;,\u0026#34;Pvcl\u0026#34;,\u0026#34;Pve\u0026#34;,\u0026#34;Pvl\u0026#34;,\u0026#34;RiverTrack\u0026#34;,\u0026#34;Holocene\u0026#34;,\u0026#34;Holocene (Alluvial Valley)\u0026#34;,\u0026#34;Holocene (Deltaic and Chenier Plains)\u0026#34;,\u0026#34;Pleistocene\u0026#34;],[\u0026#34;Principal abandoned deltaic distributaries. Distributaries grouped together and not separately delineated.\u0026#34;,\u0026#34;Undifferentiated alluvium of small streams.\u0026#34;,\u0026#34;Backswamp (floodbasin) deposits.\u0026#34;,\u0026#34;Cheniers and relict beach ridges.\u0026#34;,\u0026#34;Abandoned channels (neck and chute cutoffs) of the Mississippi River.\u0026#34;,\u0026#34;Abandoned courses of the Mississippi River. Projected where removed by later subsequent small streams. Includes trunk channels of major delta complexes.\u0026#34;,\u0026#34;Projected where removed by lateral migration of subsequent small streams. Includes trunk channels of major delta complexes.\u0026#34;,\u0026#34;Undifferentiated paludal deposits of chenier plain. Represents brackish to saline marsh environments.\u0026#34;,\u0026#34;Interdistributary deposits. Represents brackish to saline marsh environments.\u0026#34;,\u0026#34;Lacustrine and lacustrine deltaic deposits of the Atchafalaya Basin.\u0026#34;,\u0026#34;Inland swamp deposits. Represents freshwater swamp environment.\u0026#34;,\u0026#34;Natural levees in deltaic plain associated with major distributaries and present Mississippi River. Natural levees that overlie interdistributary and other deltaic deposits, but not point bar deposits, are grouped together and not separately delineated.\u0026#34;,\u0026#34;Point bar (meander scroll) …","date":1571270400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"6096871ad43a702729238d5048abddaf","permalink":"https://lizroten.com/post/fisk-s-mississippi-river-meander-in-r/","publishdate":"2019-10-17T00:00:00Z","relpermalink":"/post/fisk-s-mississippi-river-meander-in-r/","section":"post","summary":"Background Those of us even mildly obsessed with maps will be familiar with Harold Fisk’s 1944 series documenting the historic travel of the Mississippi River in Mississippi River Alluvial Valley.","tags":["cartography","arcgis","ggplot2"],"title":"Fisk's 'Mississippi River Meander' in R","type":"post"},{"authors":["Liz Roten"],"categories":null,"content":"","date":1570492800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657646074,"objectID":"63f0c0f523b71f3f1c5f4628f8ec6052","permalink":"https://lizroten.com/talk/wilmds-streetlight-parks/","publishdate":"2019-10-08T00:00:00Z","relpermalink":"/talk/wilmds-streetlight-parks/","section":"talk","summary":"StreetLight Data provides aggregated cell phone location data for transportation research. This talk will examine how the Research Team at the Metropolitan Council is using StreetLight to analyze visitor patterns in regional parks, with particuar focus on novel geospatial processing and statisitical methods.","tags":["Metropolitan Council","StreetLight Data","Parks"],"title":"Using location-based services to locate high activity areas within Twin Cities regional parks","type":"talk"},{"authors":null,"categories":null,"content":"Summary To better understand activity within Como Regional Park and how that activity shifts with the seasons, I created a hexagon grid over the park and then used aggregated and anonymized location-based services data provided by StreetLight Data to measure relative activity in each hexagon.\nThis project was my first endeavor with Tableau and was used as a pilot before we dedicated additional resources to using StreetLight Data for parks research.\nDetails StreetLight Data Data in this data visualization comes from StreetLight, an independent data provider which cleans, processes and assimilates millions of spatial data points from a combination of mobile phone Location-Based Services (LBS) data and GPS data. The data is anonymized, aggregated, and accessed only through specific analyses.\nThis viz draws on LBS data. Cell phone apps that use LBS collect the device’s location in space and time. StreetLight detects trips, a movement with clear start and stop locations. StreetLight uses trips to create the StreetLight Traffic Index, which is a normalized measure of the relative traffic, or activity, in an area. The data’s spatial precision is 65ft or better and StreetLight estimates a 23% penetration rate for the combined US and Canada adult population.\nAnalysis For this viz, we made a hexagon grid over Como Regional Park. We then ran a StreetLight analysis to measure the relative traffic in each hexagon and repeated the analysis for Winter (November 2017 - February 2018), Summer (May 2018 - August 2018), and all 2018. StreetLight returns a Traffic Index value for each hexagon for every trip intersection type, day type, and day part configuration.\nInteractive Map In the Tableau viz, you can view the analysis results. Each hexagon on the map changes color according to its Traffic Index, or activity level. The darker the color, the higher the traffic. You can view the exact Traffic Index value of any hexagon by hovering over it. Use the map tools in the upper left corner to pan, zoom, and adjust the map view. We suggest you view this story in full screen for the best display.\n","date":1561075200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"d2f23d1027d50272b923e9186fb28341","permalink":"https://lizroten.com/project/como-hex-streetlight-parks/","publishdate":"2019-06-21T00:00:00Z","relpermalink":"/project/como-hex-streetlight-parks/","section":"project","summary":"Visualize high activity areas within Como Regional Park and seasonal trends","tags":["Metropolitan Council","StreetLight Data","parks","Tableau","interactive","visualization"],"title":"Como Regional Park Hex Grid StreetLight Analysis","type":"project"},{"authors":["Liz Roten"],"categories":null,"content":"","date":1559952000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657646074,"objectID":"1ced15f14dc52b9b09b05d1880fe908d","permalink":"https://lizroten.com/talk/tcrg-streetlight-parks/","publishdate":"2019-06-08T00:00:00Z","relpermalink":"/talk/tcrg-streetlight-parks/","section":"talk","summary":"StreetLight Data provides aggregated cell phone location data for transportation research. This talk will examine how the Research Team at the Metropolitan Council is using StreetLight to analyze visitor patterns in regional parks.","tags":["Metropolitan Council","StreetLight Data","Parks"],"title":"Using Location-based Data in Regional Parks Visitors Research","type":"talk"},{"authors":["Liz Roten"],"categories":null,"content":" Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650135358,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://lizroten.com/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":["cartography"],"content":"A map I made during my time at Macalester College.\n","date":1510185600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"812dbeca1080b9e9ac86e5fb372bd057","permalink":"https://lizroten.com/post/hiv-and-african-american-populations-in-the-us/","publishdate":"2017-11-09T00:00:00Z","relpermalink":"/post/hiv-and-african-american-populations-in-the-us/","section":"post","summary":"A map I made during my time at Macalester College.","tags":["design","map","arcgis","bivariate choropleth","HIV","health disparities","epidemiology","cartography"],"title":"HIV and African American Populations in the US","type":"post"},{"authors":[],"categories":["cartography"],"content":" View a higher resolution of this viz here   About the Process I use eMoods to track my mental health from day to day. For this viz, I used eMoods data, as well as my Google Location History data, to display my life between February 2015 and October 2017. I used ggplot2 in R Studio to generate the radial bar charts on the far rights, and Adobe Illustrator to construct the bar graphs in the bottom left corner. For the heatmaps, I first attempted to use ArcGIS to view data I downloaded from my Google account directly but quickly found that software to be limiting for the goals of this project I forked and modified Location History Visualizer using JavaScript, HTML, and CSS to use my own color scheme and preferred base map. I assembled the images in Adobe Illustrator and presented this work for my class.\nI worked with geospatial data in formats I was unfamiliar with, such as KML, JSON, and tar.gz zipped files. I also had no prior experience in Adobe Illustrator, JavaScript, HTML, and CSS. This piece not only demonstrates my skill in these areas but also my persistence and commitment to telling my story.\nDuring my Spring 2018 independent project, I also used R Shiny to take a simple, interactive look at the polar coordinate bar graphs. You can see this app on its own here and the updated version here.\n\n","date":1509321600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"e19291c7bbf3dc6339568b0b9b6a371e","permalink":"https://lizroten.com/post/3-years-of-mental-health-a-quantified-self-story/","publishdate":"2017-10-30T00:00:00Z","relpermalink":"/post/3-years-of-mental-health-a-quantified-self-story/","section":"post","summary":"View a higher resolution of this viz here   About the Process I use eMoods to track my mental health from day to day. For this viz, I used eMoods data, as well as my Google Location History data, to display my life between February 2015 and October 2017.","tags":["arcgis","ggplot2","design","illustrator","personal","Shiny"],"title":"3 Years of Mental Health: A quantified-self story","type":"post"},{"authors":null,"categories":["cartography"],"content":" View a higher resolution of this viz here   About the Process I use eMoods to track my mental health from day to day. For this viz, I used eMoods data, as well as my Google Location History data, to display my life between February 2015 and October 2017. I used ggplot2 in R Studio to generate the radial bar charts on the far rights, and Adobe Illustrator to construct the bar graphs in the bottom left corner. For the heatmaps, I first attempted to use ArcGIS to view data I downloaded from my Google account directly but quickly found that software to be limiting for the goals of this project I forked and modified Location History Visualizer using JavaScript, HTML, and CSS to use my own color scheme and preferred base map. I assembled the images in Adobe Illustrator and presented this work for my class.\nI worked with geospatial data in formats I was unfamiliar with, such as KML, JSON, and tar.gz zipped files. I also had no prior experience in Adobe Illustrator, JavaScript, HTML, and CSS. This piece not only demonstrates my skill in these areas but also my persistence and commitment to telling my story.\nDuring my Spring 2018 independent project, I also used R Shiny to take a simple, interactive look at the polar coordinate bar graphs. You can see this app on its own here and the updated version here.\n","date":1509321600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"343d70e4529f380d8eb00003a39162e9","permalink":"https://lizroten.com/project/3-years-of-mental-health-a-quantified-self-story/","publishdate":"2017-10-30T00:00:00Z","relpermalink":"/project/3-years-of-mental-health-a-quantified-self-story/","section":"project","summary":"Mapping my travel patterns and mental health from 2015-2017","tags":["arcgis","ggplot2","design","illustrator","personal","shiny"],"title":"3 Years of Mental Health: A quantified-self story","type":"project"},{"authors":["Liz Roten","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650135358,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://lizroten.com/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Liz Roten","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650135358,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://lizroten.com/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650135358,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://lizroten.com/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650138358,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://lizroten.com/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650138358,"objectID":"8e7bc052bdfc6746ea2bb6595e8093eb","permalink":"https://lizroten.com/home/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"6087c0ef875554f4409ac52928d79279","permalink":"https://lizroten.com/projects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/projects/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"My blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650138358,"objectID":"53e892b8b41cc4caece1cfd5ef21d6e7","permalink":"https://lizroten.com/license/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/license/","section":"","summary":"My blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n   ","tags":null,"title":"LICENSE: CC-BY-SA","type":"page"},{"authors":null,"categories":null,"content":"Congrats! You found my stash of favorite internet things. Mostly sfw. Enjoy!\nTweets ASMR for developers pic.twitter.com/KGF3H8nY5z\n— Cassidy (@cassidoo) June 24, 2020  Toddler v.s. Husky\nI have watched this approximately 9,345,678 times so far today pic.twitter.com/6ND1H1qAMF\n— lisa bizzle (@Lisa_Bizzle) November 9, 2019  Videos Taylor Swift + Goats\n  “Look at all those chickens!”\n  T-Rex family + school bus\n  Pure Joy ©️ Katelyn Ohashi\n  Did you know that Alan Tudyk went to Julliard?\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656607410,"objectID":"ee8e33cdefe407f8a813eb78a2c36f95","permalink":"https://lizroten.com/favorite-things/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/favorite-things/","section":"","summary":"Congrats! You found my stash of favorite internet things. Mostly sfw. Enjoy!\nTweets ASMR for developers pic.twitter.com/KGF3H8nY5z\n— Cassidy (@cassidoo) June 24, 2020  Toddler v.s. Husky\nI have watched this approximately 9,345,678 times so far today pic.","tags":null,"title":"Favorite things","type":"page"}]